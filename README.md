# 🔥AI烽火：大模型时代的征途

> 10年算法专家团队的工程实战笔记
> 从理论到实践，从入门到精通的完整学习路径
> 四大主线：基础理论、实战竞赛、求职面试、数学基础

## 前沿
[🔥 DeepSeek-OCR爆火！把万字长文压缩成一张图，AI长文本瓶颈被这样颠覆](https://github.com/Decalogue/flyllm/blob/main/llm/DeepSeek-OCR.md)


## 一、基础理论
> 大模型架构、专题分享、代码解析

[Tokenizer 完全指南](https://github.com/Decalogue/flyllm/blob/main/llm/Tokenizer.md)

[Transformer 上篇：起源与革命](https://github.com/Decalogue/flyllm/blob/main/llm/Transformer_1.md)

[Transformer 中篇：架构与实践](https://github.com/Decalogue/flyllm/blob/main/llm/Transformer_2.md)

[Transformer 下篇：扩张与未来](https://github.com/Decalogue/flyllm/blob/main/llm/Transformer_3.md)

[大模型时代，BERT还有价值吗？](https://github.com/Decalogue/flyllm/blob/main/llm/Bert.md)

[为什么现代大模型都采用因果解码器（Decoder-only）架构？](https://github.com/Decalogue/flyllm/blob/main/llm/Causal.md)

[为什么LoRA能用极少参数微调大模型？](https://github.com/Decalogue/flyllm/blob/main/llm/LoRA.md)

[为什么QLoRA能在消费级GPU上微调65B大模型？](https://github.com/Decalogue/flyllm/blob/main/llm/QLoRA.md)

### 1.专题-DeepSeek
[DeepSeek-R1 训练细节](https://github.com/Decalogue/flyllm/blob/main/llm/DeepSeek-R1.md)

[DeepSeek-V3 训练细节](https://github.com/Decalogue/flyllm/blob/main/llm/DeepSeek-V3.md)

[DeepSeek 是怎么训练 MoE 模型的？](https://github.com/Decalogue/flyllm/blob/main/llm/DeepSeek.md)

### 2.专题-RL
[系统梳理8种主流LLM强化学习算法](https://github.com/Decalogue/flyllm/blob/main/llm/RL.md)

[PPO](https://github.com/Decalogue/flyllm/blob/main/llm/PPO.md)

[GRPO](https://github.com/Decalogue/flyllm/blob/main/llm/GRPO.md)

[DAPO](https://github.com/Decalogue/flyllm/blob/main/llm/DAPO.md)

[DAPO 相比 GRPO 改进了什么](https://github.com/Decalogue/flyllm/blob/main/llm/RL.md)


## 二、实战竞赛
> AI比赛深度复盘、topk 方案对比分析、比赛经验分享

[第四届琶洲算法大赛国际AI赛 | 跨语言多模态可解释的情感识别](https://github.com/Decalogue/flyllm/blob/main/competition/PaZhou.md)

### Kaggle


## 三、求职面试
> 算法题解、面试技巧、简历优化

[LeetCode](https://github.com/Decalogue/flyllm/blob/main/algorithm/README.md)


## 四、数学基础
> 线性代数、概率统计、优化理论

[Math](https://github.com/Decalogue/flyllm/blob/main/math/README.md)
