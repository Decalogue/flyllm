# LLM & Agent & Memory & 系统架构 & Leetcode

---

## 💡 复习规划

> 基于科学学习理论：主动回忆（Active Recall）、费曼学习法（Feynman Technique）

### 核心学习方法

#### 1. 主动回忆（Active Recall）
- **不看书回答**：先尝试回忆知识点，再对照答案
- **自我测试**：定期用问题列表自测，不看答案先回答
- **手撕代码**：不看示例代码，先自己实现
- **讲给别人听**：用费曼学习法，尝试向他人解释概念
- **定期自测**：每周固定时间自测所有知识点
- **随机提问**：不按顺序，随机抽取问题回答
- **错题集**：记录答错的问题，重点复习
- **模拟面试**：模拟真实面试场景，限时回答问题

#### 2. 费曼学习法（Feynman Technique）
- **选择概念**：选择一个要掌握的概念
- **简单解释**：用最简单的语言向"初学者"解释
- **找出盲点**：发现解释不清楚的地方，重新学习
- **简化类比**：用类比和例子让概念更易懂
- **实践应用**：将概念应用到实际问题中，验证理解

### 学习节奏

#### 每日任务
1. **新知识点学习**：1-2个新问题（深度学习）
2. **主动回忆**：随机抽取3-5个问题，不看答案回答
3. **手撕代码**：至少完成1个代码实现（限时30分钟）
4. **费曼学习法**：选择1个概念，尝试用简单语言解释

#### 每周任务
1. **全面自测**：用问题列表全面自测一次
2. **错题复习**：复习本周答错的所有问题
3. **知识总结**：用费曼学习法总结本周学习的核心概念
4. **模拟面试**：模拟真实面试，完整回答2-3个问题

#### 每月任务
1. **知识体系梳理**：整理知识图谱，查漏补缺
2. **实战项目回顾**：回顾实际项目经验，与理论结合
3. **学习效果评估**：评估掌握程度，调整学习计划

### 各模块重点

#### LLM（基础架构 + 后训练）
- **核心重点**：Transformer架构、Attention机制、Fine-tuning、RLHF
- **学习方法**：手撕代码 + 架构图绘制 + 原理讲解
- **复习频率**：高频（2-3天一次）

#### Agent
- **核心重点**：ReAct框架、Function Calling、多轮对话、规划能力
- **学习方法**：框架对比 + 实际应用 + 问题场景分析
- **复习频率**：高频（2-3天一次）

#### Memory
- **学习方式**：参考 `memory/` 目录下的专门笔记
- **学习方法**：论文阅读 + 架构对比 + 实际应用

#### 系统架构
- **核心重点**：架构设计原则、技术选型、性能优化、成本控制
- **学习方法**：实际项目经验 + 架构设计练习 + 案例分析
- **复习频率**：中频（1周一次）

#### Leetcode
- **学习方法**：分类练习 + 模板总结 + 错题重刷
- **复习频率**：中频（1周一次）

---

## 🎯 准备建议（团队负责人视角）

### 回答问题的框架
1. **业务理解**：先说明业务场景和需求，展现商业思维
2. **技术深度**：展示核心技术细节，体现专家能力
3. **系统思维**：考虑性能、成本、扩展性、可维护性等综合因素
4. **实践案例**：结合具体项目经验，展现实战能力
5. **团队协作**：说明如何与技术、产品、运营等团队协作
6. **风险管控**：展示风险识别和应对能力

### 重点展示的能力
- **技术领导力**：技术选型、架构决策、技术规划
- **业务理解**：理解业务目标，技术服务于业务
- **系统思维**：全链路思考，考虑各个环节
- **团队管理**：团队协作、知识传承、人才培养
- **沟通能力**：向上汇报、跨部门协作、技术布道
- **问题解决**：快速定位问题，提出有效解决方案

### 项目深挖准备（面试官视角）
面试官通常会针对你的主要项目深挖，需要准备：

1. **数据相关**
   - 数据合成的方法和流程（如何生成、质量如何保证）
   - 数据规模和分布（训练集、验证集、测试集的划分）
   - 数据质量评估方法和指标

2. **训练相关**
   - Loss 的具体设计和计算过程（数学公式、代码实现）
   - 训练超参数的选择（学习率、batch size、epochs等）和调优过程
   - 训练过程中的问题和解决方案（收敛问题、过拟合、遗忘等）
   - 训练效率和成本（训练时间、GPU使用、成本优化）

3. **工程实现**
   - 关键技术点的实现细节（如 vLLM 的并行机制、PagedAttention 等）
   - 性能优化的具体方法（延迟、吞吐量、内存等）
   - 遇到的工程问题和解决方案

4. **结果评估**
   - 评估指标的选择和计算方式
   - 实验结果和对比分析
   - 实际效果和业务价值

**准备技巧**：每个核心项目准备一个"项目深挖"文档，包含上述所有要点，确保能够深入回答任何相关问题。

---

## 📋 问题列表

### LLM

#### Tokenizer
1. 什么是分词器？为什么 LLM 需要分词而不是直接处理字符？
2. BPE 算法的核心思想是什么？能详细说说它的训练和编码过程吗？
3. SentencePiece 和 BPE 有什么区别？为什么 GPT 系列用 BPE，而 T5 用 SentencePiece？
4. WordPiece 和 BPE 的区别在哪里？BERT 为什么选择 WordPiece？
5. Unigram Language Model Tokenizer 的工作原理是什么？它有什么优势？
6. 为什么子词分词比词级分词更适合大模型？遇到稀有词怎么处理？
7. 词汇表大小如何确定？太大会怎样，太小会怎样？
8. 特殊标记 [CLS]、[SEP]、[PAD]、[MASK] 分别起什么作用？为什么需要它们？

#### Transformer & Attention
1. Transformer 的核心架构是什么？为什么它成为所有 LLM 的基础？Encoder 和 Decoder 的区别在哪里？
2. 自注意力机制的数学公式是什么？Q、K、V 分别代表什么？为什么要除以 sqrt(d_k)？
3. 为什么需要多头注意力？多头比单头好在哪里？头数怎么选择？
4. Cross-Attention 和 Self-Attention 有什么区别？分别用在什么场景？
5. 注意力机制的计算复杂度是 O(n²)，如何优化？有哪些降低复杂度的方法？
6. 因果掩码（Causal Mask）是什么？为什么自回归模型需要它？怎么实现？
7. 稀疏注意力有哪些实现方式？Longformer 和 BigBird 的区别是什么？
8. 局部注意力适用于什么场景？窗口大小怎么设计？
9. 线性注意力如何降低复杂度？Performer 和 Linformer 的区别是什么？
10. GQA（分组查询注意力）是什么？为什么 LLaMA 2 用它？它如何平衡性能和效率？
11. Longformer 的滑动窗口注意力是怎么实现的？窗口大小怎么选？
12. Flash Attention 解决了什么问题？它的核心思想是什么？Flash Attention 2 改进了什么？
13. 注意力权重可视化能告诉我们什么？如何分析模型的注意力模式？
14. 注意力机制会出现梯度消失吗？如何缓解？
15. 位置偏置（Position Bias）是什么？如何消除？
16. 位置编码有哪些方式？绝对位置编码和相对位置编码的区别是什么？
17. RoPE 的原理是什么？为什么它能外推到更长序列？怎么实现的？
18. ALiBi 是什么？它如何实现位置编码？和 RoPE 比有什么优势？
19. LayerNorm 和 BatchNorm 的区别是什么？为什么 Transformer 用 LayerNorm？
20. RMSNorm 是什么？它和 LayerNorm 的区别？为什么 LLaMA 用 RMSNorm？
21. 预训练、微调、指令微调的区别是什么？各自的目标是什么？
22. 模型并行、数据并行、流水线并行有什么区别？如何选择？能混合使用吗？
23. ZeRO 优化器如何减少显存？ZeRO-1、ZeRO-2、ZeRO-3 的区别是什么？
24. SFT 和 RLHF 的区别是什么？各自的优缺点？
25. 大模型的上下文长度限制是怎么产生的？如何扩展上下文窗口？有哪些方法？

#### Fine-tuning
1. 全量微调和参数高效微调的区别是什么？什么时候用全量微调？
2. LoRA 的原理是什么？rank 和 alpha 参数怎么选？为什么有效？
3. QLoRA 如何进一步降低显存？4-bit 量化怎么实现？精度损失大吗？
4. Adapter 和 LoRA 的区别是什么？各自的适用场景？
5. 指令微调的数据怎么构建？指令格式怎么设计？需要多少数据？
6. 数据合成（Data Synthesis）有哪些方法？如何生成高质量的SFT数据？合成数据的质量如何评估？
7. SFT 训练中的 Loss 如何设计？交叉熵损失的具体计算过程是什么？如何处理不平衡的数据分布？
8. SFT 之后出现灾难性遗忘（Catastrophic Forgetting）的原因是什么？如何解决？有哪些具体方法？
9. 多任务微调如何平衡不同任务？损失函数怎么设计？如何避免任务间的负迁移？
10. 微调的学习率怎么设置？初始学习率怎么选？需要 Warmup 吗？学习率调度策略如何选择？
11. 早停机制怎么设计？验证指标怎么选？patience 怎么设置？如何防止过拟合？
12. 微调的数据增强有哪些方法？如何设计增强策略？如何保证增强后的数据质量？

#### RL & RLHF
1. 强化学习的基本概念是什么？如何应用到 LLM 训练？
2. Policy Gradient 方法的核心思想是什么？REINFORCE 算法如何计算梯度？
3. Actor-Critic 方法是什么？价值函数和策略函数如何训练？
4. PPO 为什么比 REINFORCE 更稳定？它的核心改进是什么？
5. RLHF 的完整流程是什么？每一步具体怎么做？
6. 奖励模型如何训练？奖励函数怎么设计？需要多少数据？
7. DPO 相比 RLHF 的优势是什么？如何实现？为什么更简单？
8. KL 散度惩罚为什么需要？KL 系数怎么设置？太大太小会怎样？
9. 奖励函数怎么设计？奖励黑客是什么？如何防止？
10. 离线强化学习如何应用到 LLM？有哪些挑战？
11. 探索与利用如何平衡？在 LLM 训练中如何体现？
12. 价值函数如何用神经网络表示？如何训练？

#### RAG
1. RAG 的核心思想是什么？为什么有效？解决了什么问题？
2. RAG 系统的检索模块怎么设计？有哪些检索方法？怎么选择？
3. 向量检索和关键词检索的区别？如何结合？混合检索怎么设计？
4. Dense Retrieval 和 Sparse Retrieval 的区别？BM25 和 DPR 的区别？
5. Hybrid Search 如何实现？权重怎么平衡？
6. 向量数据库怎么选？Milvus、Pinecone、Weaviate、Qdrant 的区别？
7. Rerank 为什么需要？如何选择 Rerank 模型？什么时候用？
8. 文档分块策略怎么设计？有哪些方法？块大小怎么选？
9. RAG 中的上下文窗口限制怎么处理？长文档如何优化？
10. Query Expansion 如何优化查询？查询重写怎么实现？

#### Inference
1. 模型推理的流程是什么？有哪些关键步骤？如何优化？
2. KV Cache 如何加速推理？如何实现？内存怎么优化？
3. vLLM 的 PagedAttention 机制是什么？如何实现 KV Cache 的内存管理？
4. vLLM 的并行机制有哪些？Tensor Parallelism、Pipeline Parallelism、Data Parallelism 在 vLLM 中如何结合？
5. vLLM 的 Continuous Batching 如何实现？如何动态调度请求？相比静态批处理有什么优势？
6. 批量推理如何优化？批处理策略怎么设计？动态批处理怎么实现？
7. 流式推理如何实现？如何优化流式输出？用户体验如何提升？
8. 推理量化有哪些方法？INT8、INT4、INT1 的区别？如何选择？量化后的精度损失如何评估？
9. 推理缓存如何设计？缓存策略有哪些？如何管理缓存？缓存命中率如何提升？
10. 推理延迟和吞吐量如何优化？如何平衡延迟和准确性？性能瓶颈如何定位和优化？

### Agent

#### Agent Framework
1. AI Agent 和传统 LLM 的区别是什么？有哪些类型？
2. ReAct 框架如何实现？提示怎么设计？
3. Tool Calling 如何让模型学会使用工具？工具描述怎么设计？
4. Agent 的规划能力如何设计？有哪些规划方法？如何实现？
5. Multi-Agent 系统如何实现？Agent 之间如何协作？通信机制怎么设计？
6. Agent 的记忆机制有哪些类型？如何实现？
7. Agent 的反思能力如何实现？反思机制怎么设计？
8. Agent 的决策流程如何设计？有哪些决策框架？如何选择？
9. LangChain 的核心组件是什么？Agent 系统怎么设计？
10. Agent 的自主性如何控制？控制机制怎么设计？
11. Agent 的长期记忆和短期记忆如何实现？记忆系统怎么设计？
12. Agent 的错误恢复机制如何设计？重试策略怎么设计？

#### Function Call
1. Function Call 的多轮对话如何处理？为什么这是最难的部分？
2. Function Calling 的格式是什么？JSON Schema 如何定义？Schema 怎么设计？
3. 如何让模型学会选择合适的函数？训练方法有哪些？训练数据怎么设计？
4. Function Call 的参数提取错误如何处理？错误处理机制怎么设计？
5. Function Call 的流式输出如何实现？流式调用如何优化？
6. Function Call 的并行调用如何实现？并行调用如何管理？
7. Function Call 的验证机制如何设计？参数如何校验？验证规则怎么设计？
8. Function Call 的多轮交互如何维护上下文？上下文管理怎么设计？
9. Function Call 的链式调用如何实现？依赖关系如何处理？依赖图怎么设计？
10. Function Call 的容错机制如何设计？调用失败如何处理？重试策略怎么设计？
11. Function Call 的权限控制如何实现？如何限制可调用函数？权限系统怎么设计？
12. Function Call 的延迟如何优化？如何平衡准确性和速度？

### Memory

> 注：Memory 相关的问题和笔记请参考 `memory/` 目录下的专门笔记。

### 系统架构

#### 架构设计原则
1. AI 系统架构设计有哪些核心原则？如何平衡性能、成本、复杂度？
2. 如何设计可扩展的 AI 系统架构？扩展性如何评估？
3. 微服务架构和单体架构在 AI 系统中如何选择？各自的适用场景？
4. 领域驱动设计（DDD）如何应用到 AI 系统架构中？
5. 如何设计高可用的 AI 系统？容错和降级策略怎么设计？
6. 系统架构的演进路径如何规划？如何平滑过渡？
7. 如何设计可观测的系统架构？监控、日志、追踪如何设计？
8. 系统架构的性能如何评估和优化？性能指标有哪些？
9. 如何设计安全的系统架构？安全防护体系怎么构建？
10. 系统架构的成本如何优化？如何平衡性能和成本？
11. 技术债务如何管理？架构重构的策略是什么？
12. 如何设计跨云、混合云的 AI 系统架构？
13. 边缘计算和云端计算如何结合？架构如何设计？
14. 系统架构的标准化如何推进？如何统一技术栈？
15. 如何评估架构设计的质量？架构评审的标准是什么？

#### 技术选型与评估
1. 如何选择适合的 LLM 推理框架？vLLM、TensorRT-LLM、TGI 的区别？
2. 向量数据库如何选型？Milvus、Pinecone、Weaviate、Qdrant 的对比？
3. 消息队列在 AI 系统中如何选择？Kafka、RabbitMQ、Pulsar 的区别？
4. 如何选择模型存储方案？对象存储、分布式文件系统如何选择？
5. 缓存系统如何选择？Redis、Memcached、本地缓存的使用场景？
6. 数据库选型策略是什么？关系型、NoSQL、向量数据库如何组合？
7. 如何评估开源框架的成熟度？选型标准有哪些？
8. 自研还是使用开源框架？决策标准是什么？
9. 技术栈的统一性如何平衡？如何避免技术栈碎片化？
10. 新技术的引入流程是什么？如何评估风险？
11. 技术选型如何考虑团队能力？如何平衡技术先进性和团队能力？
12. 如何评估技术的可维护性？长期维护成本如何考虑？
13. 技术选型的文档如何规范？决策记录如何管理？
14. 如何与产品、业务团队协作，共同完成技术选型？
15. 技术选型的成本如何评估？ROI 如何计算？

#### 性能优化与扩展性
1. AI 系统的性能瓶颈通常在哪里？如何识别和优化？
2. 推理服务的延迟如何优化？端到端延迟如何降低？
3. 系统吞吐量如何提升？如何设计高吞吐的架构？
4. 模型推理的批处理如何设计？动态批处理和静态批处理的选择？
5. 系统如何支持弹性扩展？自动扩缩容的策略是什么？
6. 资源利用率如何优化？GPU、CPU、内存如何平衡？
7. 系统缓存策略如何设计？多级缓存如何设计？
8. 数据库性能如何优化？读写分离、分库分表如何设计？
9. 网络延迟如何优化？CDN、边缘节点如何利用？
10. 系统负载如何评估？容量规划如何做？
11. 性能测试如何设计？压力测试、性能基准如何建立？
12. 系统性能监控如何设计？性能指标如何定义？
13. 性能优化的优先级如何确定？如何平衡优化成本？
14. 系统扩展性如何设计？水平扩展和垂直扩展的选择？
15. 性能优化的效果如何评估？优化ROI如何计算？

#### 安全与合规
1. AI 系统的安全威胁有哪些？如何防范？
2. 模型服务的安全如何保障？认证、授权如何设计？
3. 数据安全如何保护？数据加密、脱敏如何实施？
4. 模型安全如何保障？模型攻击如何防护？
5. 系统访问控制如何设计？权限管理体系如何构建？
6. 安全审计如何实现？日志、监控如何设计？
7. 合规要求如何满足？数据隐私、算法公平性如何保障？
8. 安全漏洞如何管理？漏洞扫描、修复流程如何设计？
9. 安全事件如何响应？应急响应流程是什么？
10. 安全培训如何开展？团队安全意识如何提升？
11. 第三方安全评估如何做？安全测试如何实施？
12. 安全架构如何设计？纵深防御策略是什么？
13. 安全成本如何控制？安全性和可用性如何平衡？
14. 合规审计如何应对？审计材料如何准备？
15. 安全文化建设如何推进？安全规范如何落地？

#### 团队协作与项目管理
1. AI 团队的组织架构如何设计？角色如何划分？
2. 技术团队的协作流程如何设计？开发、测试、上线流程？
3. 敏捷开发在 AI 项目中的应用？迭代如何规划？
4. 技术债务如何管理？如何平衡新功能和重构？
5. 代码质量如何保证？Code Review、测试如何规范？
6. 知识管理如何推进？技术文档、知识库如何建设？
7. 技术培训如何开展？团队技术能力如何提升？
8. 跨团队协作如何推进？与产品、运营、算法团队如何配合？
9. 项目优先级如何管理？资源如何分配？
10. 项目风险如何识别和管理？风险应对策略是什么？
11. 项目进度如何跟踪？里程碑如何设定？
12. 团队绩效如何评估？技术贡献如何衡量？
13. 技术招聘如何进行？如何评估候选人能力？
14. 团队文化建设如何推进？如何提升团队凝聚力？
15. 技术影响力如何提升？技术分享、开源如何推进？

#### 成本控制与ROI
1. AI 系统的成本构成有哪些？如何优化？
2. 模型训练的算力成本如何优化？资源调度如何设计？
3. 推理服务的成本如何控制？如何提升资源利用率？
4. 数据存储成本如何优化？冷热数据如何分层？
5. 系统运维成本如何降低？自动化运维如何设计？
6. 人力成本如何优化？如何提升开发效率？
7. 第三方服务成本如何控制？如何避免厂商锁定？
8. 成本监控体系如何设计？成本分析如何做？
9. 成本预算如何制定？如何跟踪和控制？
10. 成本优化的优先级如何确定？ROI如何评估？
11. 如何向上级汇报成本情况？如何争取资源？
12. 成本控制与性能如何平衡？如何找到平衡点？
13. 成本优化项目如何推进？如何获得团队支持？
14. 成本意识如何培养？如何让团队关注成本？
15. 成本优化效果如何评估？如何持续改进？

#### 架构演进与重构
1. 系统架构如何演进？演进路径如何规划？
2. 架构重构的时机如何判断？什么时候需要重构？
3. 架构重构如何推进？如何降低风险？
4. 遗留系统如何处理？迁移策略是什么？
5. 新老系统如何并存？兼容性如何保证？
6. 架构重构的ROI如何评估？如何证明重构价值？
7. 重构过程中的风险如何控制？如何保证业务连续性？
8. 重构团队如何组织？如何获得支持？
9. 架构演进的技术债务如何处理？
10. 如何设计向前兼容的架构？版本管理如何设计？
11. 架构重构的测试策略是什么？如何保证质量？
12. 架构重构的沟通如何做好？如何管理变更？
13. 架构演进如何与业务发展对齐？如何支撑业务？
14. 架构演进的知识如何传承？文档如何维护？
15. 架构演进的评估如何做？如何衡量效果？

#### 跨团队协作与沟通
1. 如何与技术团队有效沟通？技术方案如何讲解？
2. 如何与产品团队协作？需求如何理解和转化？
3. 如何与算法团队协作？模型和系统如何集成？
4. 如何与运维团队协作？部署、监控如何配合？
5. 如何与业务团队协作？技术如何支撑业务？
6. 跨部门项目如何推进？如何获得支持？
7. 技术冲突如何解决？如何达成共识？
8. 技术方案如何向上汇报？如何展示价值？
9. 技术分享如何组织？如何提升影响力？
10. 技术标准如何统一？如何推进落地？
11. 技术沟通的文档如何规范？如何提升效率？
12. 远程协作如何高效？工具如何选择？
13. 跨时区协作如何协调？如何保证沟通？
14. 技术决策如何透明？如何让团队参与？
15. 技术文化建设如何推进？如何营造氛围？

#### 业务理解与技术实现
1. 如何理解业务需求？业务目标如何转化为技术目标？
2. 技术方案如何匹配业务场景？如何选择最合适的方案？
3. 业务优先级如何理解？技术工作如何排序？
4. 业务指标如何定义？技术指标如何与业务指标对齐？
5. 业务增长如何支撑？系统容量如何规划？
6. 业务创新如何支持？快速试错如何实现？
7. 业务风险如何识别？技术如何防范？
8. 业务数据如何理解？数据如何驱动决策？
9. 业务模式如何理解？技术如何支撑？
10. 业务成功如何定义？技术如何贡献？
11. 业务变化如何应对？架构如何适应？
12. 业务需求如何评估？技术可行性如何判断？
13. 业务价值如何量化？技术投入如何评估？
14. 业务理解如何提升？如何深入了解业务？
15. 技术与业务的平衡如何把握？如何避免过度设计？

#### 技术领导力
1. 技术愿景如何制定？技术路线图如何规划？
2. 技术团队如何培养？人才梯队如何建设？
3. 技术标准如何制定？如何推进落地？
4. 技术债务如何管理？如何平衡新功能和重构？
5. 技术创新如何推进？如何鼓励创新？
6. 技术风险如何识别和控制？风险应对策略是什么？
7. 技术决策如何做出？决策依据是什么？
8. 技术冲突如何解决？如何达成共识？
9. 技术影响力如何提升？如何扩大影响？
10. 技术传承如何实现？知识如何沉淀？
11. 技术文化建设如何推进？如何营造氛围？
12. 技术招聘如何进行？如何吸引人才？
13. 技术培训如何开展？如何提升团队能力？
14. 技术绩效如何评估？如何激励团队？
15. 技术领导力如何提升？如何成为优秀的技术Leader？

---

## 💻 手撕代码清单
### LLM

#### Tokenizer
1. 实现 BPE（Byte Pair Encoding）算法的核心逻辑，包括合并规则学习和编码过程
2. 实现分词器的编码（encode）和解码（decode）函数，支持特殊标记处理
3. 实现词汇表构建算法，包括词频统计、子词合并、词汇表大小控制
4. 实现 WordPiece 的分词逻辑，包括子词切分和未知词处理
5. 实现多语言分词器的语言检测和切换逻辑
6. 实现分词器的批处理功能，支持并行编码和解码

#### Transformer & Attention
1. 实现 Multi-Head Attention（MHA），包括 Q、K、V 的线性变换、多头分割、注意力计算和拼接
2. 实现 Cross-Attention，包括编码器-解码器注意力机制
3. 实现分组查询注意力（GQA），包括 KV 头的分组和注意力计算
4. 实现 RoPE（Rotary Position Embedding），包括位置编码的旋转矩阵计算和应用
5. 实现 ALiBi（Attention with Linear Biases），包括位置偏置的计算
6. 实现因果掩码（Causal Mask），支持自回归模型的掩码生成
7. 实现 Layer Normalization，包括均值和方差计算、归一化和缩放
8. 实现 RMSNorm，包括均方根归一化的计算
9. 实现位置编码（Positional Encoding），包括正弦余弦位置编码的生成
10. 实现 Flash Attention 的核心算法，包括分块计算和在线 softmax
11. 实现 MoE 的专家路由算法，包括 Top-K 选择和负载均衡
12. 实现梯度裁剪（Gradient Clipping），包括按范数裁剪和按值裁剪
13. 实现学习率调度器，包括 Warmup、Cosine、Step 等调度策略
14. 实现权重初始化，包括 Xavier 和 He 初始化方法

#### Fine-tuning
1. 实现 LoRA 的前向和反向传播，包括低秩矩阵分解和参数更新
2. 实现 Adapter 层，包括下投影、上投影和残差连接
3. 实现 Prefix Tuning，包括可训练前缀的初始化和前向传播
4. 实现梯度累积逻辑，包括梯度累加和参数更新时机控制
5. 实现早停（Early Stopping）机制，包括验证指标监控和最佳模型保存
6. 实现学习率查找器（Learning Rate Finder），用于自动选择学习率

#### RL & RLHF
1. 实现 REINFORCE 算法，包括策略梯度计算和参数更新
2. 实现 PPO 算法，包括 clipped objective 和重要性采样
3. 实现 GAE（Generalized Advantage Estimation），包括优势函数和回报计算
4. 实现奖励模型的训练逻辑，包括对比损失和偏好学习
5. 实现 KL 散度惩罚项，用于 RLHF 中的分布约束
6. 实现 DPO 损失函数，包括直接偏好优化的目标函数

#### RAG
1. 实现 BM25 检索算法，包括词频、逆文档频率和得分计算
2. 实现向量检索功能，包括余弦相似度计算和 Top-K 检索
3. 实现混合检索（Hybrid Search），包括向量检索和关键词检索的融合和权重平衡
4. 实现文档分块（Chunking）算法，包括固定窗口、滑动窗口和语义分块
5. 实现 Rerank 功能，包括交叉编码器的推理和重排序
6. 实现 Query Expansion，包括查询重写和扩展词生成
7. 实现增量更新逻辑，包括新文档的索引更新和旧文档的删除

#### Inference
1. 实现 KV Cache 的数据结构和管理逻辑，包括缓存更新和内存优化
2. 实现批量推理的批处理逻辑，包括动态批处理和填充处理
3. 实现流式推理的生成器，包括 token 流式输出和缓冲管理
4. 实现模型量化的核心算法，包括 INT8、INT4 量化和反量化
5. 实现模型剪枝算法，包括结构化剪枝和非结构化剪枝
6. 实现 Speculative Decoding，包括草稿模型和验证逻辑
7. 实现连续批处理（Continuous Batching），包括请求队列管理和动态调度
8. 实现 PagedAttention 的内存管理，包括分页存储和内存分配

### Agent

#### Agent Framework
1. 实现 ReAct 框架的核心逻辑，包括推理和行动的循环
2. 实现 Agent 的状态机，包括状态转换和动作执行
3. 实现 Agent 的记忆系统，包括短期记忆和长期记忆的管理
4. 实现多 Agent 系统的通信机制，包括消息传递和协调逻辑
5. 实现 Agent 的规划算法，包括任务分解和步骤生成

#### Function Call
1. 实现 Function Call 的参数解析器，包括 JSON Schema 验证和类型转换
2. 实现 Function Call 的上下文管理器，支持多轮对话的上下文维护
3. 实现 Function Call 的链式调用逻辑，包括依赖关系解析和执行顺序
4. 实现 Function Call 的容错机制，包括错误捕获和重试策略
5. 实现 Function Call 的异步调用框架，包括并发控制和结果聚合

### Memory

> 注：Memory 相关的手撕代码请参考 `memory/` 目录下的专门笔记。

### 系统架构

#### 架构设计
1. 设计一个可扩展的AI推理服务架构，支持多模型、动态扩缩容
2. 设计一个高可用的RAG系统架构，包含检索、生成、缓存等组件
3. 设计一个完整的AI训练平台架构，支持数据管理、训练调度、模型管理
4. 设计一个多租户的AI服务平台，支持资源隔离和计费
5. 设计一个端到端的AI应用架构，包含数据处理、模型服务、前端展示
6. 设计一个混合云的AI系统架构，支持公有云和私有云
7. 设计一个边缘AI系统架构，支持边缘推理和云端训练
8. 设计一个完整的监控和告警系统，支持性能监控、错误追踪、成本分析

#### 技术选型与评估
1. 实现一个技术选型评估框架，包含技术评估、风险分析、成本估算
2. 实现一个开源框架对比工具，自动收集和对比框架特性
3. 实现一个技术债务跟踪系统，跟踪和管理技术债务
4. 实现一个架构文档生成工具，自动生成架构图和文档
5. 实现一个性能基准测试框架，用于评估系统性能

#### 成本优化
1. 实现一个成本监控系统，跟踪和分析系统成本
2. 实现一个资源调度优化器，优化GPU、CPU等资源使用
3. 实现一个成本分析工具，分析成本构成和优化机会
4. 实现一个预算管理系统，跟踪和控制成本预算
5. 实现一个成本优化建议系统，自动推荐优化方案

---

## 📊 问题准备策略

### 按角色定位准备
- **技术专家路线**：重点准备LLM、Agent、Memory等核心技术问题，展示技术深度
- **架构师路线**：重点准备系统架构、技术选型、性能优化等问题，展示系统思维
- **团队Leader路线**：重点准备团队协作、项目管理、技术领导力等问题，展示综合能力

### 按场景准备
- **技术面试**：准备核心技术问题和手撕代码
- **架构面试**：准备系统架构设计和技术选型问题
- **Leader面试**：准备团队管理、项目管理、跨部门协作问题
- **汇报展示**：准备业务理解、成本控制、ROI评估问题

### 回答技巧
1. **STAR法则**：Situation（场景）、Task（任务）、Action（行动）、Result（结果）
2. **数据支撑**：用具体数据说明问题，如性能提升50%、成本降低30%
3. **对比分析**：对比不同方案的优缺点，展现决策能力
4. **风险意识**：说明潜在风险和应对措施，展现风险管控能力
5. **持续改进**：说明后续优化方向，展现持续学习能力