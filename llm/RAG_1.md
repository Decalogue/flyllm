# RAG：全栈面试题总结（基础篇）
> 覆盖原理、检索、生成基础，适合面试突击、快速上手

**本文特色：**
- 🎯 **一句话说清原理** - 每个技术点核心机制、优劣势、适用场景一目了然
- 📊 **横向对比分析** - 多维度系统对比，快速定位最适合的方法
- 🔥 **实战经验分享** - 结合项目经验，提供工程化落地指南
- 💡 **问题解决方案** - 常见问题和优化策略，拿来即用

**涵盖内容：** RAG原理 | RAG组成与评估 | 查询改写 | 向量检索 | 关键词检索 | 混合检索

**📖 进阶内容请参考：** [RAG_2.md - 进阶篇](./RAG_2.md)

---

## 📑 快速导航

| 主题 | 核心问题 | 难度 | 推荐场景 |
|------|---------|------|---------|
| [**RAG基础原理**](#1-rag基础原理) | 什么是RAG？为什么需要RAG？ | ⭐ | 必会 |
| [**RAG组成与评估**](#rag的组成与评估) | RAG有哪些基本模块？如何评估？ | ⭐⭐ | 核心 |
| [**查询改写**](#查询改写query-rewriting) | 为什么需要查询改写？如何实现？ | ⭐⭐ | 核心 |
| [**向量检索**](#2-向量检索) | 如何实现语义检索？Embedding模型选择？ | ⭐⭐ | 核心 |
| [**关键词检索**](#3-关键词检索) | BM25原理？如何优化？ | ⭐⭐ | 核心 |
| [**混合检索**](#4-混合检索) | 如何融合多路召回？权重如何设置？ | ⭐⭐⭐ | 进阶 |

---

## 1. RAG基础原理

### 💡 一句话回答

> **核心要点：** RAG（Retrieval-Augmented Generation）是检索增强生成技术，通过**检索相关文档 + LLM生成**的方式，让模型能够基于外部知识库回答问题，**减少幻觉、提升准确性、支持知识更新**。

---

### 📝 详细回答（3-5分钟）

#### 1️⃣ 什么是RAG？

**RAG = Retrieval（检索） + Augmented（增强） + Generation（生成）**

**工作流程：**
```
1. 用户提问："什么是GRPO？"
2. 检索阶段：从知识库中检索相关文档（Top-K）
3. 增强阶段：将检索到的文档作为上下文
4. 生成阶段：LLM基于检索到的文档生成回答
```

**核心公式：**
$$P(y|x) = \sum_{z \in Z} P(z|x) \cdot P(y|x,z)$$

其中：
- $x$：用户问题
- $z$：检索到的文档
- $y$：生成的回答
- $P(z|x)$：检索概率（检索阶段）
- $P(y|x,z)$：生成概率（LLM生成）

---

#### 2️⃣ 为什么需要RAG？

**传统LLM的问题：**

| 问题 | 表现 | RAG解决方案 |
|------|------|-----------|
| **知识过时** | 训练数据截止到某个时间点 | ✅ 实时更新知识库 |
| **幻觉问题** | 生成不存在的信息 | ✅ 基于真实文档生成 |
| **知识局限** | 无法访问私有知识 | ✅ 支持私有知识库 |
| **可解释性差** | 不知道信息来源 | ✅ 可以引用源文档 |
| **成本高** | 需要重新训练模型 | ✅ 无需重新训练 |

**RAG的优势：**
- ✅ **知识更新**：只需更新知识库，无需重新训练模型
- ✅ **减少幻觉**：基于真实文档，减少编造信息
- ✅ **可解释性**：可以展示来源文档
- ✅ **成本低**：无需大规模训练，只需维护知识库

---

#### 3️⃣ RAG vs 微调

| 维度 | RAG | 微调 |
|------|-----|------|
| **知识更新** | ✅ 实时更新知识库 | ❌ 需要重新训练 |
| **成本** | ✅ 低（只需维护知识库） | ❌ 高（需要训练资源） |
| **灵活性** | ✅ 高（可切换知识库） | ❌ 低（模型固定） |
| **准确性** | ⚠️ 依赖检索质量 | ✅ 直接学习到模型中 |
| **适用场景** | 知识问答、文档理解 | 特定任务优化 |

**最佳实践：RAG + 微调结合**
- 通用知识：RAG检索
- 任务特定：微调优化

---

## RAG的组成与评估

### 💡 一句话回答

> **核心要点：** RAG系统由**查询改写、召回、精排、答案生成**四个基本模块组成，每个模块都有对应的评估指标，需要协同优化才能提升整体效果。

---

### 📝 详细回答（5-8分钟）

#### 1️⃣ RAG的基本模块

**RAG链路包含四个核心阶段：**

1. **查询改写阶段（Query Rewriting）**
   - 作用：将用户查询改写为更清晰、更易检索的查询
   - 方法：基于Prompt工程、交互式追问、Query2Doc、HyDE等

2. **召回阶段（Retrieval）**
   - 作用：从大规模文档库中检索相关文档
   - 方法：稀疏检索（BM25）、稠密检索（向量检索）、混合检索

3. **精排阶段（Reranking）**
   - 作用：对召回结果进行精细排序，提升相关性
   - 方法：Point-wise、Pair-wise、List-wise排序

4. **答案生成阶段（Answer Generation）**
   - 作用：基于检索到的文档生成最终答案
   - 方法：LLM生成、引用机制、后处理验证

**工作流程：**
```
用户查询 → 查询改写 → 召回（Top-K） → 精排（Top-N） → 答案生成
```

---

#### 2️⃣ 各模块评估指标

**召回阶段评估：**
- **Recall@K**：前K个结果中包含正确答案的比例
- **Top-K F1 Score**：综合考虑精确率和召回率

**精排阶段评估：**
- **MAP（Mean Average Precision）**：平均精确率
- **MRR（Mean Reciprocal Rank）**：平均倒数排名
- **nDCG（normalized Discounted Cumulative Gain）**：归一化折损累积增益

**答案生成阶段评估：**
- **Exact Match（精确匹配）**：生成答案与标准答案完全匹配
- **F1 Score**：生成答案与标准答案的F1分数
- **语义相似度**：使用Embedding模型计算语义相似度

> 📖 **详细评估指标计算方法请参考：** [RAG_2.md - 评估指标](./RAG_2.md#评估指标)

---

#### 3️⃣ 模块协同优化

**关键原则：**
- 各模块的优化目标可能不一致，需要协同优化
- 使用生成质量作为奖励信号，优化检索和重排阶段
- 使用高质量数据训练Reader模型，提升整体效果

---

## 查询改写（Query Rewriting）

### 💡 一句话回答

> **核心要点：** 查询改写是RAG的预检索阶段，通过LLM将用户查询改写为更清晰、更易检索的查询，缩小查询与文档之间的表达差距，提升检索效果。

---

### 📝 详细回答（3-5分钟）

#### 1️⃣ 为什么需要查询改写？

**问题：**
- 用户查询与参考文档之间存在表达差距
- 用户查询可能不够清晰或标准化
- 直接检索可能无法找到相关文档

**解决方案：**
- 使用LLM的强大生成能力改写查询
- 通过术语规范化、交互式追问等技术提升改写效果

---

#### 2️⃣ 查询改写方法

**方法1：基于Prompt的查询改写**

```python
# 示例Prompt
prompt = """
下面是一个查询，但它的表述不是很清晰，
我希望你将它表述清晰以便我搜索相关的资料：
{query}
"""
```

**方法2：Query2Doc**

- 原理：让LLM基于查询"预解答"，生成类似参考文档的文本
- 优势：即使预解答不完全正确，其结构和内容分布也与参考文档相似
- 应用：使用Few-shot示例引导LLM生成文档风格的文本

**方法3：HyDE（Hypothetical Document Embeddings）**

- 原理：生成假设性文档，然后基于假设文档进行检索
- 优势：能够更好地理解查询意图

---

#### 3️⃣ 查询改写优化

**术语规范化：**
- 将非标准术语转换为标准术语
- 使用领域词典进行映射

**交互式追问：**
- 当查询不够清晰时，主动询问用户
- 获取更多上下文信息

---

## 2. 向量检索

### 💡 一句话回答

> **核心要点：** 向量检索使用Embedding模型将文本转换为向量，通过向量相似度（如余弦相似度）检索相关文档。核心是选择合适的Embedding模型和索引方法。

---

### 📝 详细回答（3-5分钟）

#### 1️⃣ 向量检索原理

**流程：**
```
1. 文档编码：doc → embedding_model → vector (768维)
2. 问题编码：query → embedding_model → vector (768维)
3. 相似度计算：cosine_similarity(query_vec, doc_vec)
4. 排序返回：Top-K最相似的文档
```

**数学原理：**
$$\text{similarity}(q, d) = \frac{q \cdot d}{||q|| \cdot ||d||} = \cos(\theta)$$

其中$\theta$是向量夹角，值域$[-1, 1]$，越大越相似。

---

#### 2️⃣ Embedding模型选择

**主流模型对比：**

| 模型 | 维度 | 特点 | 适用场景 |
|------|------|------|---------|
| **BGE-base-zh-v1.5** | 768 | 中文优化，性能好 | 中文RAG ⭐ |
| **BGE-large-zh-v1.5** | 1024 | 性能更强，速度略慢 | 高精度需求 |
| **text-embedding-ada-002** | 1536 | OpenAI官方，多语言 | 英文场景 |
| **m3e-base** | 768 | 中文优化，开源 | 中文RAG |
| **bge-small-zh-v1.5** | 512 | 速度快，精度略低 | 实时性要求高 |
| **Sentence-BERT** | 768 | 双塔架构，基于BERT | 英文场景 |
| **SimCSE** | 768 | 对比学习，无监督 | 通用场景 |
| **SGPT** | 768-4096 | GPT架构，大参数 | 高精度需求 |

**DPR（Dense Passage Retrieval）：**
- 使用不同的编码器分别编码查询和文档
- 训练时最大化正样本相似度
- 适合大规模文档检索

**Sentence-BERT：**
- 双塔架构：查询和文档分别编码
- 使用对比学习训练
- 支持预计算文档向量，检索速度快

**SGPT（GPT Sentence Embeddings）：**
- 使用GPT架构进行句子表示
- 支持联合编码和分离编码
- 大参数模型（1.25B-61B）表现更好

**选择建议：**
- 中文场景：BGE-base-zh-v1.5（平衡性能和速度）
- 英文场景：text-embedding-ada-002
- 实时性要求高：bge-small-zh-v1.5
- 精度要求高：BGE-large-zh-v1.5

---

#### 3️⃣ 索引方法

**主流索引：**

1. **Faiss（Facebook AI Similarity Search）**
   - 支持多种索引类型（Flat、IVF、HNSW等）
   - 适合大规模向量检索
   - 支持GPU加速

2. **Milvus**
   - 向量数据库，支持分布式
   - 适合生产环境
   - 支持多种索引算法

3. **Elasticsearch + dense_vector**
   - 结合文本检索和向量检索
   - 适合混合检索场景

**索引选择：**
- 小规模（<100万）：Flat索引（精确检索）
- 中规模（100万-1亿）：IVF或HNSW（近似检索）
- 大规模（>1亿）：HNSW + 分布式

---

#### 4️⃣ 优化策略

**1. 文档分块（Chunking）**
- 问题：文档太长，检索不精准
- 方案：将长文档切分成小块（如512 tokens）
- 策略：重叠切分（overlap），保留上下文

**2. 向量维度**
- 768维：平衡性能和精度
- 1024维：更高精度，但速度慢
- 512维：速度快，但精度略低

**3. Top-K选择**
- 召回阶段：K=50-100（保证召回率）
- 最终返回：K=5-10（保证相关性）

---

## 3. 关键词检索

### 💡 一句话回答

> **核心要点：** 关键词检索使用TF-IDF和BM25算法计算查询词和文档的匹配度，适合精确匹配场景。相比向量检索，速度快、资源占用低，但语义理解能力弱。

---

### 📝 详细回答（5-8分钟）

#### 1️⃣ TF-IDF原理

**TF-IDF（Term Frequency-Inverse Document Frequency）公式：**

**词频（TF）：**
$$TF(t_i, d_j) = \frac{Count(t_i, d_j)}{|d_j|}$$

其中：
- $Count(t_i, d_j)$：词$t_i$在文档$d_j$中的出现次数
- $|d_j|$：文档$d_j$的长度（总词数）

**逆文档频率（IDF）：**
$$IDF(t_i) = \ln\left(\frac{D}{\sum_{d_j \in D} ICount(t_i, d_j)}\right)$$

其中：
- $D$：文档总数
- $ICount(t_i, d_j) = \begin{cases} 1 & \text{if } t_i \in d_j \\ 0 & \text{if } t_i \notin d_j \end{cases}$

**TF-IDF分数：**
$$TF\text{-}IDF(t_i, d_j) = TF(t_i, d_j) \times IDF(t_i)$$

**TF-IDF的局限性：**
- 基于词袋模型（Bag of Words），稀疏表示
- 语义表示能力相对较弱
- 无法处理同义词、语义相似但字面不同的情况

---

#### 2️⃣ BM25原理

**BM25（Best Matching 25）公式：**

$$\text{Score}(Q, d_j) = \sum_{i=1}^{|Q|} IDF(t_i) \times \frac{(k_1 + 1) \times TF(t_i, d_j)}{k_1 \times (1 - b + b \times \frac{|d_j|}{avgdl}) + TF(t_i, d_j)}$$

其中：
- $Q$：查询
- $t_i$：查询中的第$i$个词
- $TF(t_i, d_j)$：词$t_i$在文档$d_j$中的词频
- $IDF(t_i)$：词$t_i$的逆文档频率
- $k_1$：词频饱和度参数（通常1.2-2.0，默认1.2）
- $b$：长度归一化参数（通常0.75）
- $|d_j|$：文档$d_j$的长度
- $avgdl$：平均文档长度

**BM25相比TF-IDF的改进：**
- ✅ **词频饱和**：使用饱和函数，避免高频词过度影响
- ✅ **长度归一化**：考虑文档长度，防止长文档得分过高
- ✅ **更成熟稳定**：经过大量实践验证

**核心思想：**
- **TF（词频）**：词在文档中出现次数越多，相关性越高
- **IDF（逆文档频率）**：词在所有文档中出现越少，重要性越高
- **长度归一化**：防止长文档得分过高

---

#### 3️⃣ BM25 vs TF-IDF

| 维度 | TF-IDF | BM25 |
|------|--------|------|
| **词频处理** | 线性增长 | 饱和函数（防止过度依赖高频词） |
| **长度归一化** | ❌ 无 | ✅ 有 |
| **性能** | 快 | 快 |
| **适用场景** | 简单匹配 | 精确匹配 ⭐ |

**BM25优势：**
- ✅ 词频饱和：避免高频词过度影响
- ✅ 长度归一化：公平对待长短文档
- ✅ 成熟稳定：经过大量实践验证

---

#### 4️⃣ 优化策略

**1. 中文分词**
- 使用jieba、HanLP等分词工具
- 支持自定义词典（领域术语）

**2. 停用词过滤**
- 移除"的"、"了"等无意义词
- 提升检索效率

**3. 同义词扩展**
- 扩展查询词的同义词
- 提升召回率

---

## 4. 混合检索

### 💡 一句话回答

> **核心要点：** 混合检索结合向量检索和关键词检索，通过加权融合或重排序的方式，兼顾语义理解和精确匹配，通常能获得比单一方法更好的效果。

---

### 📝 详细回答（3-5分钟）

#### 1️⃣ 为什么需要混合检索？

**单一方法的局限：**

| 方法 | 优势 | 劣势 |
|------|------|------|
| **向量检索** | 语义理解强 | 精确匹配弱，可能漏检 |
| **关键词检索** | 精确匹配强 | 语义理解弱，同义词漏检 |

**混合检索优势：**
- ✅ 兼顾语义和精确匹配
- ✅ 提升召回率和准确率
- ✅ 适应不同查询类型

---

#### 2️⃣ 融合方法

**方法1：加权融合（Reciprocal Rank Fusion）**

```python
def rrf_fusion(vector_scores, keyword_scores, k=60):
    # 计算RRF分数
    vector_rrf = 1 / (k + vector_ranks)
    keyword_rrf = 1 / (k + keyword_ranks)
    
    # 加权融合
    final_scores = α * vector_rrf + (1-α) * keyword_rrf
    
    return final_scores
```

**方法2：加权求和**

```python
# 归一化分数
vector_norm = normalize(vector_scores)
keyword_norm = normalize(keyword_scores)

# 加权融合
final_scores = 0.7 * vector_norm + 0.3 * keyword_norm
```

**权重设置：**
- 语义查询多：向量权重0.7-0.8
- 精确查询多：关键词权重0.5-0.6
- 平衡场景：各0.5

---

#### 3️⃣ 实际应用

**项目经验（AI助手）：**
- 语义向量召回：使用BGE-base-zh-v1.5，召回语义相似的文档
- 关键词召回：使用BM25，精确匹配文档名称、风格等
- 融合方式：加权融合（向量0.7，关键词0.3）
- 效果：召回率提升15%，准确率提升8%

---

## ❓ 面试高频追问（基础篇）

### Q1: RAG和微调有什么区别？什么时候用RAG？

**标准回答：**

**区别：**
- RAG：检索外部知识，无需训练，知识可更新
- 微调：将知识学习到模型中，需要训练，知识固定

**选择原则：**
- 知识经常更新 → RAG
- 任务特定优化 → 微调
- 最佳实践：RAG + 微调结合

---

### Q2: 如何解决RAG中的幻觉问题？

**标准回答：**

1. **提升检索质量**：使用更好的Embedding模型、混合检索
2. **重排序**：使用Rerank提升相关性（详见进阶篇）
3. **提示工程**：在Prompt中强调"基于检索到的文档回答"
4. **后处理验证**：检查生成内容是否在检索文档中
5. **引用机制**：要求模型引用来源文档

---

### Q3: 向量检索和关键词检索如何选择？

**标准回答：**

**向量检索适合：**
- 语义查询（"如何优化模型性能？"）
- 同义词场景（"汽车"和"车辆"）
- 语义相似但字面不同

**关键词检索适合：**
- 精确匹配（"BERT模型"）
- 专业术语（"GRPO算法"）
- 名称、日期等精确信息

**最佳实践：混合检索**

---

### Q4: 如何评估RAG系统效果？

**标准回答：**

**评估指标：**
1. **检索指标**：Recall@K、MRR（平均倒数排名）
2. **生成指标**：BLEU、ROUGE、语义相似度
3. **端到端指标**：准确率、用户满意度
4. **系统指标**：延迟、吞吐量、错误率

**评估方法：**
- 人工评估：标注相关性、准确性
- 自动评估：使用评估数据集
- A/B测试：对比不同方案

> 📖 **详细评估指标计算方法请参考：** [RAG_2.md - 评估指标](./RAG_2.md#评估指标)

---

## 🎯 核心速查

**RAG工作流程：**
```
用户提问 → 查询改写 → 检索相关文档 → 增强上下文 → LLM生成回答
```

**关键技术：**
- 查询改写：Query2Doc、HyDE
- 向量检索：BGE-base-zh-v1.5、Faiss
- 关键词检索：BM25
- 混合检索：加权融合、RRF

**性能指标：**
- 检索延迟：<200ms
- 生成延迟：<3s
- 准确率：Top-1 >80%

---

## 📚 参考资料

**论文：**
- RAG (2020): "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks"
- DPR (2020): "Dense Passage Retrieval for Open-Domain Question Answering"
- Sentence-BERT (2019): "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"

**工具：**
- Faiss: https://github.com/facebookresearch/faiss
- Milvus: https://milvus.io/
- BGE: https://github.com/FlagOpen/FlagEmbedding

---

## 🎯 记住三点

> 1. **核心**：检索 + 增强 + 生成
> 2. **基础**：向量检索 + 关键词检索 + 混合检索
> 3. **价值**：减少幻觉、支持知识更新

---

## 📖 继续学习

**进阶内容请参考：** [RAG_2.md - 进阶篇](./RAG_2.md)

进阶篇包含：
- 重排序（Rerank）和多阶段召回
- 上下文管理
- 多路召回
- 评估指标详解（MAP、MRR、nDCG）
- 工程优化
- RAG工程化问题（7个痛点）

