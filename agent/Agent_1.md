# Agent 面试实战 - 上篇

---

## 一、Agent 基础理论（必考）

### 1. AI Agent 和传统 LLM 的区别是什么？有哪些类型？

**核心区别**：
- **LLM**：被动响应，只能基于训练数据生成文本，无法主动获取信息或执行操作
- **Agent**：主动决策，具备自主性、工具使用、记忆管理和规划执行能力

**本质差异**：
1. **能力边界**：LLM 受限于训练数据，Agent 通过工具调用突破边界
2. **执行模式**：LLM 是单次生成，Agent 是循环执行（ReAct循环）
3. **状态管理**：LLM 无状态，Agent 维护对话状态和任务上下文
4. **可验证性**：LLM 输出不可验证，Agent 可通过工具结果验证

**公式**：Agent = LLM + 工具 + 记忆 + 规划 + 执行

**Agent 分类**：
1. **按数量**：单Agent（独立任务）vs Multi-Agent（协作任务）
2. **按行为模式**：反应式（低延迟）vs 规划式（高准确率）vs 混合式（ReAct）
3. **按功能**：工具型（Function Calling）vs 对话型（Conversational）vs 混合型
4. **按领域**：通用Agent（GPT-4、Claude）vs 专业领域Agent（代码、研究、教育）

**面试深入问题**：
- **Q：为什么需要 Agent？LLM 直接调用 API 不行吗？**
  - A：LLM 无法维护状态、无法处理多步依赖、无法验证结果。Agent 通过状态机管理整个流程。

- **Q：Agent 和 RAG 的区别？**
  - A：RAG 是检索增强生成，被动检索；Agent 是主动决策执行，可以调用工具、维护状态、规划任务。

---

### 2. 什么是 ReAct 框架？它的核心思想是什么？

**ReAct 框架**：Reasoning（推理）+ Acting（行动）的循环机制，由 Yao et al. 在 2022 年提出

**核心思想**：
- **推理（Reasoning）**：分析当前情况，思考下一步行动，生成可解释的推理过程
- **行动（Acting）**：调用工具执行具体操作，获取外部信息或执行任务
- **观察（Observation）**：获取工具执行结果，作为下一轮推理的输入

**循环流程**：
```
思考 → 行动 → 观察 → 思考 → 行动 → ... → 完成
```

**相比传统方法的优势**：
1. **可解释性**：推理过程可见，便于调试和优化
2. **准确性提升**：通过工具验证减少幻觉（相比纯 LLM 提升 10-20%）
3. **动态调整**：可根据工具结果调整策略
4. **错误恢复**：工具失败时可重新推理

**提示设计要点**：
- **格式规范**：明确推理步骤（Thought: ...）、行动步骤（Action: tool_name）、观察结果（Observation: ...）
- **Few-shot 示例**：提供 2-3 个完整示例帮助模型理解格式
- **停止条件**：明确何时输出 Final Answer
- **工具描述**：包含名称、参数、用途、示例

**面试深入问题**：
- **Q：ReAct 和 Chain-of-Thought 的区别？**
  - A：CoT 只有推理，ReAct 是推理+行动循环，可以调用工具获取实时信息。

- **Q：ReAct 的局限性？如何改进？**
  - A：局限性：可能过度推理、工具选择错误、无法并行。改进：Reflexion（反思机制）、Self-Consistency（多路径投票）、Tree of Thoughts（树状推理）。

---

### 3. Agent 的自主性如何体现？如何控制 Agent 的自主性？

**自主性体现**：
1. **自主决策**：根据任务和目标自主选择工具和策略，无需人工干预
2. **主动探索**：主动获取信息，不依赖用户提供所有细节（如 AutoGPT 的自主搜索）
3. **动态调整**：根据执行结果调整策略和计划，具备自我纠错能力
4. **多步推理**：能够分解复杂任务，执行多步骤操作（如研究 Agent 的多跳检索）

**控制自主性的方法**：
1. **边界控制**：
   - **工具白名单**：限制可用工具列表，防止越权操作
   - **权限管理**：基于用户角色和任务类型动态分配工具权限
   - **任务范围**：定义任务边界，拒绝超出范围的任务
   - **参数验证**：严格验证工具参数，防止注入攻击

2. **安全机制**：
   - **危险操作确认**：删除、修改等操作需要用户确认
   - **执行步数限制**：设置最大执行步数（通常 10-20 步），防止无限循环
   - **异常监控**：监控异常行为（如频繁失败、异常工具调用），触发告警
   - **成本控制**：设置 Token 消耗上限，防止成本失控

3. **策略约束**：
   - **预设执行策略**：为特定任务类型预设执行路径
   - **推理深度限制**：限制推理步骤，避免过度推理
   - **工具调用频率**：限制同一工具的调用频率，防止滥用

**面试深入问题**：
- **Q：如何平衡自主性和安全性？**
  - A：分级控制（高/中/低自主性级别）、实时监控、A/B 测试找到最优平衡点。关键是在保证安全的前提下最大化效率。

- **Q：Agent 失控的常见原因？如何预防？**
  - A：原因：无限循环、工具选择错误、状态管理混乱。预防：步数限制、状态快照、异常检测、成本上限。

---

### 4. 为什么需要 Agent？LLM 的局限性在哪里？

**LLM 的局限性**：
1. **无法获取实时信息**：训练数据有截止时间（如 GPT-4 截止到 2023 年 4 月），无法获取最新信息
2. **无法调用外部工具**：不能执行计算、搜索、API 调用等操作，能力受限
3. **缺乏长期记忆**：每次对话都是独立的，无法记住历史信息（上下文窗口有限）
4. **多步推理能力弱**：难以执行需要多步骤、多工具协作的复杂任务
5. **无法验证结果**：生成的内容可能包含错误或幻觉（幻觉率 5-15%）
6. **无法执行操作**：只能生成文本，无法实际操作（如发送邮件、修改代码）

**Agent 的价值**：
- **能力扩展**：通过工具调用扩展能力边界，支持实时搜索、代码执行等
- **长期记忆**：通过记忆机制实现长期学习，记住用户偏好和历史
- **复杂任务**：通过规划能力处理复杂任务，分解多步骤操作
- **准确性提升**：通过实时信息获取和工具验证，减少幻觉（可降低至 2-5%）
- **可操作性**：能够实际执行操作，而不仅仅是生成文本

**实际应用场景**：
- **代码 Agent**：GitHub Copilot、Cursor，可执行代码、运行测试
- **研究 Agent**：Perplexity、Claude，可实时搜索、整合信息
- **办公 Agent**：可发送邮件、创建文档、管理日程
- **数据分析 Agent**：可查询数据库、生成报告、可视化

**面试深入问题**：
- **Q：Agent 一定能解决 LLM 的所有问题吗？**
  - A：不是。Agent 增加了复杂性和成本，需要状态管理、错误处理。对于简单任务，纯 LLM 可能更高效。关键是选择合适的场景。

---

## 二、ReAct 框架（高频）

### 5. ReAct 框架如何实现？提示怎么设计？

**实现步骤**：
1. **初始化**：接收用户任务，初始化状态（对话历史、工具列表、执行步数）
2. **推理循环**：
   - 调用 LLM 进行推理（Thought），生成下一步计划
   - 解析 LLM 输出，提取行动指令（Action），使用正则或 JSON 解析
   - 执行工具调用（Acting），支持同步/异步执行
   - 获取工具结果（Observation），处理成功/失败/超时
3. **判断停止**：检查是否完成任务或达到停止条件（步数/时间/错误）
4. **返回结果**：输出最终答案，清理资源

**提示模板设计要点**：
- **格式规范**：使用明确的标记（Thought/Action/Observation），便于解析
- **工具描述**：包含名称、参数、用途、示例，帮助模型理解
- **Few-shot 示例**：提供 2-3 个完整示例，展示正确格式
- **停止条件**：明确何时输出 Final Answer
- **错误处理**：定义错误情况下的处理方式

**工程优化**：
- **输出解析**：使用结构化输出（JSON 模式）提高解析成功率（从 85% 提升至 98%）
- **工具匹配**：使用向量检索快速匹配最相关工具，降低延迟
- **结果缓存**：缓存相同工具调用结果，减少重复调用（节省 30-50% 成本）
- **并行执行**：无依赖工具并行执行，降低总延迟（可降低 40-60%）

**面试深入问题**：
- **Q：如何提高 ReAct 的执行效率？**
  - A：并行执行无依赖工具、结果缓存、工具预加载、智能停止（检测到信息已足够时提前停止）。

- **Q：ReAct 解析失败怎么办？**
  - A：多层解析策略：JSON 模式 → 正则提取 → LLM 修复。记录失败模式，优化提示。

---

### 6. ReAct 中的推理（Reasoning）和行动（Acting）如何平衡？

**平衡原则**：
1. **推理时机**：
   - **任务开始时**：分析任务，制定计划，识别所需工具（1-2 步推理）
   - **工具调用前**：选择合适的工具和参数，验证参数完整性
   - **获得结果后**：分析结果，决定下一步（继续/停止/调整策略）

2. **行动时机**：
   - **明确需要外部信息时**：立即调用搜索工具，不要过度推理
   - **需要执行操作时**：参数齐全后立即执行，避免犹豫
   - **需要计算时**：直接调用计算工具，不要手动计算

3. **避免过度推理**：
   - **设置推理深度限制**：每步推理不超过 200 tokens
   - **优先行动获取信息**：信息不足时先获取信息再推理
   - **避免在信息不足时过度思考**：设置"信息不足"阈值，直接行动

**平衡策略**：
- **简单任务**：推理 1 步，行动 1-2 次（推理占比 20-30%）
- **中等任务**：推理 2-3 步，行动 3-5 次（推理占比 30-40%）
- **复杂任务**：推理 3-5 步，行动 5-10 次（推理占比 40-50%）

**最佳实践**：
1. **先行动后推理**：获取足够信息后再深入分析，避免"纸上谈兵"
2. **推理要简洁**：聚焦关键决策点，避免冗长分析（控制在 100-200 tokens）
3. **行动要果断**：明确目标后立即执行，减少犹豫
4. **结果驱动**：根据工具结果决定下一步，而非预设计划

**面试深入问题**：
- **Q：如何判断推理是否过度？**
  - A：指标：推理 token 数、推理时间占比、重复推理。如果推理占比 >50% 或重复推理，说明过度。

- **Q：推理和行动的成本如何权衡？**
  - A：推理成本低但可能不准确，行动成本高但结果可靠。策略：简单决策少推理，关键决策多推理。

---

### 7. 如何设计 ReAct 的停止条件？

**停止条件类型**：
1. **任务完成**：
   - 检测到 "Final Answer" 标记（最理想情况）
   - 任务目标已达成（通过结果验证）
   - 用户问题已解决（语义相似度判断）

2. **步数限制**：
   - 设置最大执行步数（通常 10-20 步，复杂任务可到 30 步）
   - 防止无限循环（常见问题：工具返回结果触发新工具调用）
   - 控制成本和延迟（每步成本约 0.01-0.05 元）

3. **错误重试**：
   - 连续失败次数限制（通常 3 次，可配置）
   - 错误类型判断（可重试：网络超时；不可重试：参数错误）
   - 降级处理机制（返回部分结果或错误信息）

4. **超时控制**：
   - 单步执行超时（通常 30-60 秒）
   - 总执行时间限制（通常 2-5 分钟）
   - 工具调用超时（通常 10-30 秒）

5. **其他条件**：
   - **结果质量**：检测到结果质量足够好时提前停止
   - **成本上限**：Token 消耗达到上限时停止
   - **用户中断**：用户主动取消时停止

**实现思路**：
- 多条件组合判断（任务完成 OR 步数限制 OR 超时 OR 错误过多）
- 动态调整限制（根据任务复杂度）
- 优雅降级（达到限制时返回当前最佳结果，而非直接失败）
- 监控告警（记录停止原因，分析优化方向）

**面试深入问题**：
- **Q：如何判断任务是否完成？**
  - A：多维度判断：Final Answer 标记、结果质量分数、语义相似度、用户反馈。使用分类模型判断（准确率 90%+）。

- **Q：停止条件如何动态调整？**
  - A：根据任务复杂度（简单任务 5 步，复杂任务 20 步）、历史成功率、成本预算动态调整。

---

## 三、Tool Calling / Function Calling（极高概率）

### 8. Tool Calling 如何让模型学会使用工具？工具描述怎么设计？

**训练方法**：
1. **Few-shot 学习**：在提示中提供工具使用示例（2-5 个），适合小规模场景
2. **SFT（Supervised Fine-tuning）**：使用工具调用数据微调模型，效果最好（准确率提升 20-30%）
3. **RLHF（Reinforcement Learning）**：通过奖励信号优化工具选择，适合复杂场景
4. **混合训练**：结合 Few-shot + SFT，兼顾效果和成本

**数据构建**：
- **工具调用对**：<用户查询, 工具调用> 配对数据
- **多轮对话**：包含追问、工具链的完整对话
- **错误样本**：包含错误调用和纠正，提升鲁棒性
- **数据量**：通常需要 1 万-10 万条高质量数据

**工具描述设计要点**：
1. **清晰的描述**：说明工具用途、使用场景、何时使用
2. **详细的参数说明**：每个参数的类型、含义、示例、约束
3. **明确的必填项**：标注 required 字段，帮助模型理解
4. **使用示例**：提供典型使用场景，最好 2-3 个
5. **参数约束**：enum、pattern、min/max 等，帮助模型生成正确参数

**工程实践**：
- **工具分类**：按功能分类（搜索、计算、操作），便于模型选择
- **向量化描述**：工具描述向量化，快速匹配（相似度 >0.8）
- **动态工具列表**：根据任务类型动态加载相关工具，减少干扰
- **工具版本管理**：工具更新时保持向后兼容，避免模型混淆

**面试深入问题**：
- **Q：如何评估工具调用的效果？**
  - A：指标：工具选择准确率（90%+）、参数提取准确率（85-95%）、调用成功率（95%+）。通过 A/B 测试对比不同训练方法。

- **Q：工具描述写不好会有什么问题？**
  - A：工具选择错误、参数提取错误、调用失败率高。关键：描述要具体、示例要典型、约束要明确。

---

### 9. Function Calling 的格式是什么？JSON Schema 如何定义？

**OpenAI Function Calling 格式**：
- **模型输出**：包含 `tool_calls` 数组，每个元素包含 `id`、`type`、`function`（name + arguments）
- **系统处理**：解析 `arguments`（JSON 字符串），执行工具，返回结果
- **结果返回**：以 `function` role 返回工具结果，模型继续生成

**JSON Schema 定义要点**：
- `name`: 工具名称（唯一标识）
- `description`: 工具描述（帮助模型理解何时使用）
- `parameters`: 参数定义（JSON Schema 格式）
  - `type`: 参数类型（string, integer, boolean, object, array）
  - `description`: 参数说明（帮助模型理解）
  - `enum`: 枚举值（限制可选值，提高准确率）
  - `pattern`: 正则表达式（验证格式，如日期、邮箱）
  - `default`: 默认值（可选参数）
  - `required`: 必填字段列表
  - `properties`: 嵌套对象定义（复杂参数）

**设计最佳实践**：
1. **描述要具体**：说明工具用途、使用场景、输入输出示例
2. **参数要明确**：每个参数都要有 description，帮助模型理解
3. **约束要合理**：enum 和 pattern 要准确，避免过度限制
4. **必填要清晰**：required 字段要准确，避免遗漏关键参数

**常见问题**：
- **Schema 过于宽松**：模型容易生成错误参数 → 增加 enum、pattern 约束
- **Schema 过于严格**：模型无法生成有效参数 → 放宽约束或提供更多示例
- **描述不清晰**：模型选择错误工具 → 优化 description，增加使用场景

**面试深入问题**：
- **Q：JSON Schema 设计不好会导致什么问题？**
  - A：参数提取错误率高、工具调用失败、模型困惑。关键：描述要准确、约束要合理、示例要典型。

- **Q：如何处理 Schema 版本兼容？**
  - A：向后兼容原则：只增不改、新增字段设为可选、废弃字段标记 deprecated、版本号管理。

---

### 10. Function Call 的多轮对话如何处理？为什么这是最难的部分？

**核心观点**：多轮对话不是 NLP，是状态机。它不只是语言理解，而是流程调度逻辑。

**为什么最难？**

模型需要同时理解并处理以下问题：
1. **什么情况下不能调用工具？** - 参数不足时必须追问
2. **什么情况下必须追问？** - 关键参数缺失时
3. **追问要问哪个变量？** - 一次只问一个关键变量
4. **用户回答后如何继续流程？** - 继承前文、补齐参数、继续流程
5. **工具结果如何继续下一轮？** - 工具返回后触发下一轮调用
6. **工具失败时如何 fallback？** - 错误处理和降级方案
7. **上下文参数如何"记住"？** - 状态管理和上下文维护
8. **最终答案什么时候给？** - 所有工具完成后统一生成

**完整流程**：
```
意图识别 → 信息收集 → 工具调用 → 工具结果处理 → 下一轮决策 → 最终输出
```

---

**多轮对话的三种结构**

#### ① 信息补全型多轮对话（最频繁）

**特征**：
- 参数不足时不调用工具
- 必须追问关键参数
- 一次只问一个关键变量

**示例**：
```
user: 帮我在上海外滩找酒店
assistant: 请问入住和离店日期是？
user: 下周五入住，住两晚
assistant: 调用 recommend_hotels...
```

**工程意义**：让模型学会"不瞎调用工具"，学会"停下来补齐信息"。

---

#### ② 工具链式多轮对话（最复杂）

**特征**：
- 多个工具按顺序调用
- 前一个工具的输出作为后一个工具的输入
- 工具结果可能触发下一轮调用

**示例**：
```
第1步: 推荐酒店 → call recommend_hotels
第2步: 对每家酒店做评价 → call get_hotel_reviews
第3步: 整合结果 → final_output
```

**实现要点**：
- 第一轮调用：推荐酒店工具，返回酒店列表
- 第二轮调用：对返回的每家酒店调用评价工具
- 结果整合：将所有工具结果整合后生成最终答案

这是完整的"多步工具链"，模型需要学会：工具调用顺序、结果传递、最终整合。

---

#### ③ 混合型多轮对话

**特征**：
- 结合信息补全和工具链式
- 追问 → 工具 → 追问继续 → 工具

**示例（旅行规划）**：
```
user: 帮我规划一次旅行
assistant: 请问想去哪个城市？
user: 西安
assistant: 请问什么时候出发？
user: 国庆
assistant: call search_travel_guide
assistant: call get_weather_info
assistant: final_answer
```

---

**何时追问？何时调用工具？（核心流程逻辑）**

每个工作流都有固定规则，根据变量决定是否需要追问参数。

**规则设计**：

| 工作流 | 缺失城市 | 缺失时间 | 缺失预算 | 工具调用顺序 |
|--------|---------|---------|---------|------------|
| 旅行规划 | 必须追问 | 必须追问 | 不需要 | 攻略 → 天气 |
| 问路 | 条件追问 | 不需要 | 不需要 | 地图 |
| 酒店推荐 | 追问城市 | 不问日期 | 必须追问 | 推荐 → 评价 |
| 酒店评价 | 追问酒店名 | 不需要 | 不需要 | 评价 |

**核心规则**：
1. **只要缺失的参数是"关键参数"，必须追问**
2. **但如果只缺失"非关键参数"，不能追问**

**示例（酒店推荐）**：
- 缺失城市 → 必须追问
- 缺失日期 → 不问（默认当天）
- 缺失预算 → 必须追问

这些是工程定义的严格规则，也是数据必须覆盖的内容。模型必须从数据中学习这些规则。

---

**多轮对话的数据如何生成？**

在真实工程场景中，手动编写大量多轮对话不现实。使用**沙盒生成**方法：

**核心逻辑**：
1. **根据标签选择工作流** - 确定对话类型
2. **根据变量决定是否需要追问** - 检查参数完整性
3. **自动构造反问句** - 使用模板生成追问
4. **用户回答由模板生成** - 基于用户画像生成回答
5. **工具链由代码模拟** - 自动生成工具调用序列
6. **工具返回由 mock 数据生成** - 使用模拟数据
7. **最后用 base 模型重写自然语言** - 让对话更自然

**优势**：
- 快速生成大量数据
- 保证所有分支场景都有覆盖
- 数据质量可控

---

**模型训练后如何做到"不会乱跳"？**

**常见问题**：
- 明明缺参数却直接调用工具
- 工具返回后继续调用错误工具
- 工具链顺序乱
- 工具调用结束后不收尾
- 忘记上下文参数
- 拒答逻辑失效

**根本原因**：数据没有覆盖好。

**解决方案**：

#### 1) 所有分支场景都有数据覆盖

**示例（问路）**：
- 有目的地 → 直接调用（数据覆盖）
- 无目的地 → 追问（数据覆盖）
- 无起点 → 自动使用坐标（数据覆盖）
- 工具返回为空 → 返回"查不到路线"（数据覆盖）
- 工具返回异常 → 返回 fallback 内容（数据覆盖）

所有分支都在数据中覆盖。

#### 2) 追问逻辑在每个工作流都有

**模型必须学会**：
- **继承前文** - 记住之前的对话内容
- **补齐参数** - 将用户回答整合到参数中
- **继续流程** - 参数齐全后继续执行

**示例**：
```
assistant: "请问入住和离店日期是什么时候？"
user: "下周五入住，两晚。"
→ 模型必须学会：继承"上海外滩"上下文，补齐日期参数，继续调用工具
```

#### 3) 工具链的数据要足够多

构建大量链式数据，确保模型学会：
- 工具调用的正确顺序
- 工具结果的正确处理
- 工具链的完整执行

---

**面试标准回答**

在 Function Call 微调中，多轮对话是核心难点。我把业务拆成多个工作流，每个工作流根据变量来决定是否需要追问参数。

追问完成后，再进入工具链式调用，工具结果可能触发下一轮调用，最终在所有工具完成后统一生成结果。

为了让模型真正学会流程，我使用沙盒方式构建数据：通过用户画像、query 模板、工具返回扰动、多轮追问模板等方式，为每个分支生成足够数量的数据，并保证所有分支场景都有覆盖。

最终模型可以：需要追问时追问，参数齐全时调用工具，工具链顺序正确，工具为空时 fallback，并且能保持多轮对话的一致性与连贯性。

---

**技术实现要点**

1. **状态机设计**：
   - 状态定义：init → 信息收集 → 工具调用 → 结果处理 → 完成
   - 状态转换：根据参数完整性和工具结果决定下一状态
   - 状态持久化：支持中断恢复，保存状态快照

2. **上下文维护**：
   - 对话历史：维护完整的 user/assistant/function 消息序列
   - 参数管理：提取、合并、验证用户输入中的参数
   - 工具调用历史：记录每次调用的工具、参数、结果

3. **追问逻辑**：
   - 参数检查：检查关键参数是否完整
   - 追问生成：根据缺失参数生成追问（一次只问一个）
   - 参数合并：用户回答后合并到已有参数中

---

### 11. Function Call 的参数提取错误如何处理？错误处理机制怎么设计？

**常见错误类型**：
1. **类型错误**：期望整数但得到字符串（最常见，占比 40-50%）
2. **格式错误**：日期格式不正确、URL 格式错误等（占比 20-30%）
3. **缺失参数**：必填参数未提供（占比 15-20%）
4. **值错误**：参数值超出范围、不在枚举列表中（占比 10-15%）
5. **结构错误**：JSON 解析失败、嵌套结构错误（占比 5-10%）

**错误处理机制**：
1. **参数验证**（多层验证）：
   - 第一层：检查必填字段
   - 第二层：检查类型和格式（pattern、enum）
   - 第三层：检查范围（min/max）
   - 返回错误列表和警告列表

2. **类型转换**（智能转换）：
   - 支持字符串数字转整数（"123" → 123）
   - 支持多种布尔表示（"true"/"1"/"yes" → True）
   - 支持格式修复（"2024/1/1" → "2024-01-01"）
   - 转换失败时抛出异常

3. **默认值处理**：
   - 缺失可选参数时填充默认值
   - 不覆盖已有值
   - 支持条件默认值（根据其他参数决定）

4. **错误恢复策略**（分级处理）：
   - **自动修复**：类型转换、格式修复、默认值填充（成功率 60-70%）
   - **重试**：参数错误时，提示模型重新生成（成功率 80-90%）
   - **降级**：使用默认值或简化参数
   - **拒绝**：无法修复时，返回友好错误信息

**工程实践**：
- **错误分类**：区分可修复和不可修复错误，采用不同策略
- **重试机制**：参数错误时最多重试 2-3 次，避免无限循环
- **错误日志**：记录所有错误，分析错误模式，优化工具描述
- **用户反馈**：参数错误时返回友好提示，而非技术错误信息

**面试深入问题**：
- **Q：如何提高参数提取准确率？**
  - A：优化工具描述、增加示例、智能类型转换、多层验证。从 70% 提升到 90%+。

- **Q：参数错误时如何优雅处理？**
  - A：先尝试自动修复（类型转换、格式修复），失败后提示模型重试，最后返回友好错误信息。

---

### 12. Function Call 的链式调用如何实现？依赖关系如何处理？

**链式调用场景**：
- **顺序依赖**：工具 A 的输出作为工具 B 的输入（如：搜索 → 分析）
- **并行执行**：多个工具无依赖关系，可并行执行（如：同时查询天气和交通）
- **条件执行**：根据工具结果决定是否执行下一个工具（如：搜索结果为空则不继续）
- **循环调用**：工具结果触发新的工具调用（如：多跳检索）

**实现方法**：
1. **依赖图构建**：
   - 节点：工具
   - 边：依赖关系（tool_b 依赖 tool_a 的结果）
   - 支持条件依赖（根据结果决定是否执行）

2. **拓扑排序**：
   - 使用 Kahn 算法计算执行顺序
   - 检测循环依赖（如果排序后节点数 < 总节点数，说明有循环）
   - 返回可并行执行的批次

3. **执行顺序**：
   - 按拓扑排序顺序执行
   - 解析参数中的依赖引用（如 `{tool_a.result}`）
   - 支持参数传递和结果聚合

4. **并行执行**：
   - 识别无依赖关系的工具批次
   - 使用线程池或异步执行（asyncio）
   - 聚合结果，继续下一批次

**工程实践**：
- **依赖声明**：在工具定义中声明依赖关系，自动构建依赖图
- **并行优化**：识别可并行工具，使用线程池或异步执行（可降低 40-60% 延迟）
- **结果缓存**：相同工具调用结果缓存，避免重复执行
- **条件执行**：支持基于结果的条件分支，提高灵活性
- **监控告警**：记录工具链执行时间、失败率，优化慢路径

**面试深入问题**：
- **Q：如何优化工具链的执行效率？**
  - A：并行执行无依赖工具、结果缓存、条件执行（跳过不必要的工具）、预加载常用工具。

- **Q：工具链执行失败如何处理？**
  - A：部分失败策略：关键工具失败则停止，非关键工具失败则降级或跳过。记录失败原因，优化依赖关系。

---

### 13. Function Call 的容错机制如何设计？调用失败如何处理？重试策略怎么设计？

**容错机制设计**：
1. **超时处理**：
   - 单步执行超时（通常 30-60 秒）
   - 总执行时间限制（通常 2-5 分钟）
   - 工具调用超时（通常 10-30 秒）
   - 使用信号或异步超时机制

2. **重试策略**：
   - **指数退避**：重试间隔 2^attempt 秒（1s → 2s → 4s）
   - **最大重试次数**：通常 3 次，可配置
   - **重试条件**：只重试可恢复错误（网络超时、限流）
   - **快速失败**：不可重试错误直接抛出

3. **错误分类**：
   - **可重试错误**：网络超时、临时服务不可用、限流、5xx 错误
   - **不可重试错误**：参数错误、权限不足、资源不存在、4xx 错误
   - **错误识别**：根据错误码、错误类型、错误消息判断

4. **降级方案**：
   - **工具降级**：主工具失败时使用备用工具
   - **结果降级**：返回部分结果或缓存结果
   - **功能降级**：跳过非关键工具，返回基础结果
   - **用户提示**：返回友好错误信息，引导用户重试

5. **监控和告警**：
   - **失败率监控**：记录失败率和错误类型分布
   - **告警阈值**：失败率 >5% 触发告警
   - **失败模式分析**：分析失败原因，优化工具或重试策略
   - **性能监控**：记录执行时间、重试次数、降级次数

**最佳实践**：
- **区分错误类型**：可重试 vs 不可重试，采用不同策略
- **指数退避**：避免系统压力，逐步增加重试间隔
- **合理超时**：根据工具特性设置超时时间（搜索 10s，计算 5s）
- **降级方案**：保证可用性，即使部分工具失败也能返回结果
- **详细日志**：记录错误堆栈、参数、重试次数，便于排查

**面试深入问题**：
- **Q：如何设计重试策略？**
  - A：指数退避 + 最大重试次数 + 错误分类。关键：只重试可恢复错误，避免无限重试。

- **Q：工具调用失败率高的原因？如何优化？**
  - A：原因：工具不稳定、参数错误、网络问题。优化：增加重试、优化参数验证、使用备用工具、监控告警。

---

## 总结

本文档涵盖了 Agent 面试中最核心的三个部分：
1. **Agent 基础理论**：理解 Agent 的本质、类型和必要性，掌握与 LLM 的区别
2. **ReAct 框架**：掌握推理-行动循环的实现和优化，理解平衡策略和停止条件
3. **Tool Calling**：深入理解工具调用的设计、实现和容错，特别是多轮对话的处理

**面试重点提醒**：
- 每个问题都要能说出**为什么这样设计**（设计思路）
- 要能说出**实际工程中的挑战和解决方案**（工程经验）
- 要能说出**性能、成本、可扩展性**等工程考量（系统思维）
- 代码实现要简洁，重点说思路和关键点（面经风格）

这些内容是 Agent 技术的基石，是面试中的必考重点。建议结合实际项目经验，深入理解每个概念背后的工程实践。

