# æ··åˆæ„å›¾è¯†åˆ«ï¼šä¸ºä»€ä¹ˆå¿…é¡»ç”¨å¤šæ ‡ç­¾åˆ†ç±»ï¼Ÿ

**2024-2025 æœ€æ–° SOTA æ–¹æ¡ˆ**
Multi-Intent Recognition: Latest State-of-the-Art Approaches

## ğŸ“‘ ç›®å½•

- [é—®é¢˜å®šä¹‰](#-é—®é¢˜å®šä¹‰)
- [æ ¸å¿ƒé—®é¢˜ï¼šæ˜¯å¦éœ€è¦å¤šæ ‡ç­¾åˆ†ç±»ï¼Ÿ](#-æ ¸å¿ƒé—®é¢˜æ˜¯å¦éœ€è¦å¤šæ ‡ç­¾åˆ†ç±»)
- [æœ€æ–° SOTA æ–¹æ¡ˆï¼ˆ2024-2025ï¼‰](#-æœ€æ–°-sota-æ–¹æ¡ˆ2024-2025)
  - [æ–¹æ¡ˆ1ï¼šåŸºäº Transformer çš„å¤šæ ‡ç­¾æ„å›¾åˆ†ç±»](#æ–¹æ¡ˆ1åŸºäº-transformer-çš„å¤šæ ‡ç­¾æ„å›¾åˆ†ç±»ä¸»æµ)
  - [æ–¹æ¡ˆ2ï¼šæ³¨æ„åŠ›æœºåˆ¶å¢å¼ºçš„å¤šæ„å›¾è¯†åˆ«](#æ–¹æ¡ˆ2æ³¨æ„åŠ›æœºåˆ¶å¢å¼ºçš„å¤šæ„å›¾è¯†åˆ«sota-2024)
  - [æ–¹æ¡ˆ3ï¼šåŸºäº LLM çš„é›¶æ ·æœ¬/å°‘æ ·æœ¬æ··åˆæ„å›¾è¯†åˆ«](#æ–¹æ¡ˆ3åŸºäº-llm-çš„é›¶æ ·æœ¬å°‘æ ·æœ¬æ··åˆæ„å›¾è¯†åˆ«2025-æœ€æ–°)
  - [æ–¹æ¡ˆ4ï¼šå›¾ç¥ç»ç½‘ç»œå¢å¼ºçš„å¤šæ„å›¾è¯†åˆ«](#æ–¹æ¡ˆ4å›¾ç¥ç»ç½‘ç»œå¢å¼ºçš„å¤šæ„å›¾è¯†åˆ«å‰æ²¿ç ”ç©¶)
- [æ–¹æ¡ˆå¯¹æ¯”ä¸é€‰å‹](#-æ–¹æ¡ˆå¯¹æ¯”ä¸é€‰å‹)
- [å®ç°ç»†èŠ‚](#-å®ç°ç»†èŠ‚)
- [å®æˆ˜æ¡ˆä¾‹](#-å®æˆ˜æ¡ˆä¾‹)
- [æ€§èƒ½ä¼˜åŒ–æŠ€å·§](#-æ€§èƒ½ä¼˜åŒ–æŠ€å·§)
- [å¿«é€Ÿå¼€å§‹æŒ‡å—](#-å¿«é€Ÿå¼€å§‹æŒ‡å—)

---

## ğŸ“‹ é—®é¢˜å®šä¹‰

### å•æ„å›¾ vs æ··åˆæ„å›¾ï¼ˆ"ä¸€ä¸ª" vs "å¤šä¸ª"ï¼‰

**å•æ„å›¾è¯†åˆ«ï¼ˆSingle Intentï¼‰**ï¼š
- **è¾“å…¥**ï¼šç”¨æˆ·æŸ¥è¯¢
- **è¾“å‡º**ï¼š**å•ä¸ª**æ„å›¾ç±»åˆ«ï¼ˆäº’æ–¥ï¼‰
- **ç¤ºä¾‹**ï¼š`"è®¢ä¸€å¼ æ˜å¤©å»åŒ—äº¬çš„æœºç¥¨"` â†’ `[è®¢ç¥¨]`
- **ç‰¹ç‚¹**ï¼šå°±åƒå•é€‰é¢˜ï¼Œåªèƒ½é€‰ä¸€ä¸ª

**æ··åˆæ„å›¾è¯†åˆ«ï¼ˆMulti-Intentï¼‰**ï¼š
- **è¾“å…¥**ï¼šç”¨æˆ·æŸ¥è¯¢
- **è¾“å‡º**ï¼š**å¤šä¸ª**æ„å›¾ç±»åˆ«ï¼ˆå¯å…±å­˜ï¼‰
- **ç¤ºä¾‹**ï¼š`"å¸®æˆ‘è®¢æœºç¥¨å¹¶æŸ¥è¯¢å¤©æ°”"` â†’ `[è®¢ç¥¨, æŸ¥è¯¢å¤©æ°”]`
- **ç¤ºä¾‹**ï¼š`"é€€æ¬¾å¹¶æŠ•è¯‰è¿™ä¸ªå•†å®¶"` â†’ `[é€€æ¬¾, æŠ•è¯‰]`
- **ç‰¹ç‚¹**ï¼šå°±åƒå¤šé€‰é¢˜ï¼Œå¯ä»¥åŒæ—¶é€‰å¤šä¸ª

### ä¸ºä»€ä¹ˆéœ€è¦æ··åˆæ„å›¾è¯†åˆ«ï¼Ÿï¼ˆ"ç°å®å¾ˆéª¨æ„Ÿ"ï¼‰

åœ¨å®é™…åº”ç”¨ä¸­ï¼Œç”¨æˆ·ç»å¸¸åœ¨ä¸€ä¸ªæŸ¥è¯¢ä¸­è¡¨è¾¾**å¤šä¸ªæ„å›¾**ï¼ˆè¿™æ˜¯å¸¸æ€ï¼Œä¸æ˜¯ç‰¹ä¾‹ï¼‰ï¼š

```
"è®¢ä¸€å¼ æ˜å¤©å»åŒ—äº¬çš„æœºç¥¨ï¼Œé¡ºä¾¿æŸ¥ä¸€ä¸‹åŒ—äº¬çš„å¤©æ°”"
â†’ æ„å›¾1: è®¢ç¥¨
â†’ æ„å›¾2: æŸ¥è¯¢å¤©æ°”

"æˆ‘è¦é€€æ¬¾ï¼Œè¿˜è¦æŠ•è¯‰è¿™ä¸ªå•†å®¶ï¼Œé¡ºä¾¿çœ‹çœ‹å…¶ä»–å•†å“"
â†’ æ„å›¾1: é€€æ¬¾
â†’ æ„å›¾2: æŠ•è¯‰
â†’ æ„å›¾3: å•†å“æµè§ˆ
```

**ä¼ ç»Ÿå•æ„å›¾åˆ†ç±»çš„"ç¡¬ä¼¤"**ï¼š
- âŒ **åªèƒ½è¯†åˆ«ä¸€ä¸ªæ„å›¾**ï¼Œå…¶ä»–æ„å›¾è¢«"æ— æƒ…æŠ›å¼ƒ"
- âŒ **éœ€è¦ç”¨æˆ·å¤šæ¬¡äº¤äº’**æ‰èƒ½å®Œæˆæ‰€æœ‰éœ€æ±‚ï¼ˆç”¨æˆ·ä½“éªŒå·®ï¼‰
- âŒ **æ•ˆç‡ä½**ï¼šç”¨æˆ·éœ€è¦"åˆ†æ­¥èµ°"ï¼Œä¸èƒ½"ä¸€æ­¥åˆ°ä½"

---

## ğŸ¯ æ ¸å¿ƒé—®é¢˜ï¼šæ˜¯å¦éœ€è¦å¤šæ ‡ç­¾åˆ†ç±»ï¼Ÿ

### âœ… ç­”æ¡ˆï¼š**æ˜¯çš„ï¼Œå¿…é¡»ä½¿ç”¨å¤šæ ‡ç­¾åˆ†ç±»ï¼**

**åŸå› åˆ†æï¼ˆ"ä¸ºä»€ä¹ˆå¿…é¡»"ï¼‰**ï¼š

1. **ä»»åŠ¡æœ¬è´¨**ï¼šæ··åˆæ„å›¾è¯†åˆ«æœ¬è´¨ä¸Šæ˜¯**å¤šæ ‡ç­¾åˆ†ç±»ï¼ˆMulti-Label Classificationï¼‰**é—®é¢˜
   - æ¯ä¸ªæ„å›¾ç±»åˆ«æ˜¯**ç‹¬ç«‹çš„æ ‡ç­¾**ï¼ˆä¸æ˜¯äº’æ–¥çš„ï¼‰
   - ä¸€ä¸ªæŸ¥è¯¢å¯ä»¥**åŒæ—¶æ‹¥æœ‰å¤šä¸ªæ ‡ç­¾**ï¼ˆå°±åƒå¤šé€‰é¢˜ï¼‰
   - æ ‡ç­¾ä¹‹é—´å¯èƒ½å­˜åœ¨ç›¸å…³æ€§ï¼Œä½†**ä¸äº’æ–¥**ï¼ˆå¯ä»¥å…±å­˜ï¼‰

2. **ä¸å¤šç±»åˆ†ç±»çš„åŒºåˆ«**ï¼š

| ç»´åº¦ | å¤šç±»åˆ†ç±»ï¼ˆMulti-Classï¼‰ | å¤šæ ‡ç­¾åˆ†ç±»ï¼ˆMulti-Labelï¼‰ |
|------|----------------------|------------------------|
| **è¾“å‡º** | å•ä¸ªç±»åˆ«ï¼ˆäº’æ–¥ï¼‰ | å¤šä¸ªç±»åˆ«ï¼ˆå¯å…±å­˜ï¼‰ |
| **æŸå¤±å‡½æ•°** | CrossEntropy | BCEWithLogits / Focal Loss |
| **è¯„ä¼°æŒ‡æ ‡** | Accuracy | F1-macro / F1-micro / Hamming Loss |
| **åº”ç”¨åœºæ™¯** | å•æ„å›¾è¯†åˆ« | **æ··åˆæ„å›¾è¯†åˆ«** |

3. **å®é™…æ¡ˆä¾‹**ï¼š

```python
# å•æ„å›¾ï¼ˆå¤šç±»åˆ†ç±»ï¼‰
query = "è®¢æœºç¥¨"
intent = "è®¢ç¥¨"  # åªæœ‰ä¸€ä¸ª

# æ··åˆæ„å›¾ï¼ˆå¤šæ ‡ç­¾åˆ†ç±»ï¼‰
query = "è®¢æœºç¥¨å¹¶æŸ¥è¯¢å¤©æ°”"
intents = ["è®¢ç¥¨", "æŸ¥è¯¢å¤©æ°”"]  # å¤šä¸ªæ„å›¾å…±å­˜
```

---

## ğŸ† æœ€æ–° SOTA æ–¹æ¡ˆï¼ˆ2024-2025ï¼‰

### æ–¹æ¡ˆ1ï¸âƒ£ï¼šåŸºäº Transformer çš„å¤šæ ‡ç­¾æ„å›¾åˆ†ç±»ï¼ˆä¸»æµï¼‰

#### æ¶æ„è®¾è®¡

```python
import torch
import torch.nn as nn
from transformers import AutoModel, AutoTokenizer

class MultiIntentTransformer(nn.Module):
    """
    åŸºäº Transformer çš„æ··åˆæ„å›¾è¯†åˆ«æ¨¡å‹
    
    Args:
        num_intents: æ„å›¾ç±»åˆ«æ•°é‡
        model_name: é¢„è®­ç»ƒæ¨¡å‹åç§°ï¼ˆå¦‚ "bert-base-chinese", "roberta-base"ï¼‰
        dropout: Dropout æ¯”ç‡
    """
    def __init__(self, num_intents, model_name="bert-base-chinese", dropout=0.1):
        super().__init__()
        # 1. é¢„è®­ç»ƒç¼–ç å™¨ï¼ˆBERT/RoBERTaï¼‰
        self.encoder = AutoModel.from_pretrained(model_name)
        hidden_size = self.encoder.config.hidden_size
        
        # 2. æ„å›¾åˆ†ç±»å¤´ï¼ˆå¤šæ ‡ç­¾ï¼‰
        self.intent_classifier = nn.Sequential(
            nn.Dropout(dropout),
            nn.Linear(hidden_size, 256),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(256, num_intents)  # æ¯ä¸ªæ„å›¾ä¸€ä¸ªè¾“å‡º
        )
        
    def forward(self, input_ids, attention_mask):
        """
        Args:
            input_ids: [batch_size, seq_len]
            attention_mask: [batch_size, seq_len]
        
        Returns:
            logits: [batch_size, num_intents]
        """
        # ç¼–ç 
        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)
        pooled_output = outputs.pooler_output  # [batch_size, hidden_size]
        
        # å¤šæ ‡ç­¾åˆ†ç±»ï¼ˆæ¯ä¸ªæ„å›¾ç‹¬ç«‹é¢„æµ‹ï¼‰
        logits = self.intent_classifier(pooled_output)  # [batch_size, num_intents]
        
        return logits
```

#### è®­ç»ƒè¦ç‚¹

```python
# 1. æŸå¤±å‡½æ•°ï¼šBCEWithLogitsLossï¼ˆå¤šæ ‡ç­¾æ ‡å‡†æŸå¤±ï¼‰
criterion = nn.BCEWithLogitsLoss()

# 2. æ ‡ç­¾æ ¼å¼ï¼šæ¯ä¸ªæ ·æœ¬æ˜¯äºŒè¿›åˆ¶å‘é‡
# ç¤ºä¾‹ï¼š3ä¸ªæ„å›¾ç±»åˆ«ï¼Œæ ·æœ¬æœ‰æ„å›¾0å’Œæ„å›¾2
labels = torch.tensor([[1, 0, 1]])  # [batch, num_intents]

# 3. é¢„æµ‹æ—¶ä½¿ç”¨ sigmoid + é˜ˆå€¼
probs = torch.sigmoid(logits)
predictions = (probs > 0.5).int()  # é˜ˆå€¼å¯è°ƒ
```

#### ä¼˜åŠ¿ï¼ˆ"ä¸ºä»€ä¹ˆé€‰å®ƒ"ï¼‰

- âœ… **é¢„è®­ç»ƒæ¨¡å‹åŠ æŒ**ï¼šåˆ©ç”¨ BERT/RoBERTa çš„å¼ºå¤§è¯­ä¹‰ç†è§£èƒ½åŠ›ï¼ˆç«™åœ¨å·¨äººè‚©è†€ä¸Šï¼‰
- âœ… **æ¶æ„ç®€å•**ï¼šæ˜“äºå®ç°å’Œéƒ¨ç½²ï¼ˆä¸éœ€è¦å¤æ‚çš„å›¾ç»“æ„æˆ–æ³¨æ„åŠ›æœºåˆ¶ï¼‰
- âœ… **æ•ˆæœç¨³å®š**ï¼šåœ¨å¤šä¸ªæ•°æ®é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼ˆF1-macro 0.82-0.90ï¼‰
- âœ… **è¿ç§»å­¦ä¹ å‹å¥½**ï¼šå¯å¿«é€Ÿé€‚é…æ–°é¢†åŸŸï¼ˆåªéœ€ fine-tune åˆ†ç±»å¤´ï¼‰

#### æ€§èƒ½æŒ‡æ ‡ï¼ˆå…¸å‹æ•°æ®é›†ï¼Œæ•°æ®è¯´è¯ï¼‰

- **å‡†ç¡®ç‡ï¼ˆExact Matchï¼‰**ï¼š75-85%ï¼ˆå®Œå…¨åŒ¹é…çš„æ¯”ä¾‹ï¼‰
- **F1-macro**ï¼š0.82-0.90ï¼ˆæ¯ä¸ªç±»åˆ«å•ç‹¬è®¡ç®— F1ï¼Œç„¶åå¹³å‡ï¼‰
- **F1-micro**ï¼š0.85-0.92ï¼ˆå…¨å±€è®¡ç®— F1ï¼Œæ‰€æœ‰æ ·æœ¬å’Œç±»åˆ«ä¸€èµ·ï¼‰
- **Hamming Loss**ï¼š0.08-0.15ï¼ˆé”™è¯¯æ ‡ç­¾çš„æ¯”ä¾‹ï¼Œè¶Šå°è¶Šå¥½ï¼‰

> **ğŸ’¡ æ€§èƒ½è§£è¯»**ï¼šåœ¨å…¸å‹æ•°æ®é›†ä¸Šï¼ŒTransformer å¤šæ ‡ç­¾åˆ†ç±»èƒ½è¾¾åˆ° **80%+ çš„ F1-macro**ï¼Œå·²ç»ç›¸å½“ä¸é”™äº†ã€‚ä½†è¿˜æœ‰ä¼˜åŒ–ç©ºé—´ï¼

---

### æ–¹æ¡ˆ2ï¸âƒ£ï¼šæ³¨æ„åŠ›æœºåˆ¶å¢å¼ºçš„å¤šæ„å›¾è¯†åˆ«ï¼ˆSOTA 2024ï¼‰

#### æ ¸å¿ƒåˆ›æ–°ï¼šæ„å›¾æ„ŸçŸ¥æ³¨æ„åŠ›ï¼ˆIntent-Aware Attentionï¼‰

```python
class IntentAwareAttention(nn.Module):
    """
    æ„å›¾æ„ŸçŸ¥æ³¨æ„åŠ›æœºåˆ¶
    ä¸ºæ¯ä¸ªæ„å›¾å­¦ä¹ ç‹¬ç«‹çš„æ³¨æ„åŠ›æƒé‡ï¼Œå®ç°æ„å›¾è§£è€¦
    
    Args:
        hidden_size: éšè—å±‚ç»´åº¦
        num_intents: æ„å›¾æ•°é‡
        num_heads: æ³¨æ„åŠ›å¤´æ•°
    """
    def __init__(self, hidden_size, num_intents, num_heads=8):
        super().__init__()
        self.num_intents = num_intents
        self.hidden_size = hidden_size
        
        # ä¸ºæ¯ä¸ªæ„å›¾å­¦ä¹ ç‹¬ç«‹çš„æŸ¥è¯¢å‘é‡
        self.intent_queries = nn.Parameter(
            torch.randn(num_intents, hidden_size)
        )
        
        # æ³¨æ„åŠ›è®¡ç®—ï¼ˆä½¿ç”¨å¤šå¤´æ³¨æ„åŠ›ï¼‰
        self.attention = nn.MultiheadAttention(
            hidden_size, num_heads=num_heads, batch_first=True
        )
        
    def forward(self, hidden_states):
        """
        Args:
            hidden_states: [batch_size, seq_len, hidden_size]
        
        Returns:
            intent_embeddings: [batch_size, num_intents, hidden_size]
        """
        batch_size = hidden_states.size(0)
        
        # ä¸ºæ¯ä¸ªæ„å›¾è®¡ç®—æ³¨æ„åŠ›
        intent_embeddings = []
        for i in range(self.num_intents):
            # ä½¿ç”¨æ„å›¾æŸ¥è¯¢å‘é‡ï¼Œæ‰©å±•ç»´åº¦ä¸º [batch, 1, hidden_size]
            query = self.intent_queries[i].unsqueeze(0).unsqueeze(0)  # [1, 1, hidden_size]
            query = query.expand(batch_size, 1, -1)  # [batch, 1, hidden_size]
            
            # è®¡ç®—æ³¨æ„åŠ›ï¼ˆquery ä½œä¸ºæŸ¥è¯¢ï¼Œhidden_states ä½œä¸º key å’Œ valueï¼‰
            attn_output, attn_weights = self.attention(
                query, hidden_states, hidden_states
            )
            # attn_output: [batch, 1, hidden_size]
            intent_embeddings.append(attn_output.squeeze(1))  # [batch, hidden_size]
        
        # æ‹¼æ¥æ‰€æœ‰æ„å›¾è¡¨ç¤º
        intent_embeddings = torch.stack(intent_embeddings, dim=1)
        # [batch_size, num_intents, hidden_size]
        
        return intent_embeddings
```

#### å®Œæ•´æ¨¡å‹æ¶æ„

```python
class IntentAwareModel(nn.Module):
    """
    æ„å›¾æ„ŸçŸ¥æ¨¡å‹ï¼šä½¿ç”¨ç‹¬ç«‹çš„æ³¨æ„åŠ›æœºåˆ¶ä¸ºæ¯ä¸ªæ„å›¾ç”Ÿæˆè¡¨ç¤º
    """
    def __init__(self, num_intents, model_name="bert-base-chinese", dropout=0.1):
        super().__init__()
        self.encoder = AutoModel.from_pretrained(model_name)
        hidden_size = self.encoder.config.hidden_size
        
        # æ„å›¾æ„ŸçŸ¥æ³¨æ„åŠ›
        self.intent_attention = IntentAwareAttention(hidden_size, num_intents)
        
        # æ„å›¾åˆ†ç±»å™¨ï¼ˆæ¯ä¸ªæ„å›¾ç‹¬ç«‹ï¼Œè¾“å‡ºå•ä¸ª logitï¼‰
        self.intent_classifier = nn.Sequential(
            nn.Dropout(dropout),
            nn.Linear(hidden_size, 128),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(128, 1)  # æ¯ä¸ªæ„å›¾è¾“å‡ºä¸€ä¸ª logit
        )
        
    def forward(self, input_ids, attention_mask):
        """
        Args:
            input_ids: [batch_size, seq_len]
            attention_mask: [batch_size, seq_len]
        
        Returns:
            logits: [batch_size, num_intents]
        """
        # ç¼–ç 
        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)
        hidden_states = outputs.last_hidden_state  # [batch, seq_len, hidden_size]
        
        # æ„å›¾æ„ŸçŸ¥æ³¨æ„åŠ›
        intent_embeddings = self.intent_attention(hidden_states)
        # [batch, num_intents, hidden_size]
        
        # æ¯ä¸ªæ„å›¾ç‹¬ç«‹åˆ†ç±»
        logits = self.intent_classifier(intent_embeddings).squeeze(-1)
        # [batch, num_intents]
        
        return logits
```

#### ä¼˜åŠ¿ï¼ˆ"ä¸ºä»€ä¹ˆæ›´å¥½"ï¼‰

- âœ… **æ„å›¾è§£è€¦**ï¼šæ¯ä¸ªæ„å›¾æœ‰ç‹¬ç«‹çš„æ³¨æ„åŠ›æƒé‡ï¼Œæ›´ç²¾å‡†ï¼ˆå°±åƒç»™æ¯ä¸ªæ„å›¾é…äº†"ä¸“å±æ˜¾å¾®é•œ"ï¼‰
- âœ… **å¯è§£é‡Šæ€§**ï¼šå¯ä»¥å¯è§†åŒ–æ¯ä¸ªæ„å›¾å…³æ³¨å“ªäº›è¯ï¼ˆçŸ¥é“æ¨¡å‹"åœ¨çœ‹ä»€ä¹ˆ"ï¼‰
- âœ… **æ€§èƒ½æå‡**ï¼šæ¯”åŸºç¡€ Transformer é«˜ **2-5% F1**ï¼ˆä» 0.85 æå‡åˆ° 0.87-0.90ï¼Œæå‡æ˜æ˜¾ï¼‰

---

### æ–¹æ¡ˆ3ï¸âƒ£ï¼šåŸºäº LLM çš„é›¶æ ·æœ¬/å°‘æ ·æœ¬æ··åˆæ„å›¾è¯†åˆ«ï¼ˆ2025 æœ€æ–°ï¼‰

#### æ ¸å¿ƒæ€è·¯ï¼šåˆ©ç”¨ LLM çš„æŒ‡ä»¤ç†è§£èƒ½åŠ›

```python
import json
import re
from transformers import AutoModelForCausalLM, AutoTokenizer

class LLMMultiIntentRecognizer:
    """
    åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ··åˆæ„å›¾è¯†åˆ«
    ä¼˜åŠ¿ï¼šé›¶æ ·æœ¬ã€å°‘æ ·æœ¬èƒ½åŠ›å¼ºï¼Œæ— éœ€å¤§é‡æ ‡æ³¨æ•°æ®
    
    æ³¨æ„ï¼šé€‚åˆå¿«é€ŸåŸå‹å’Œå¼€æ”¾åŸŸåœºæ™¯ï¼Œç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨æ··åˆæ–¹æ¡ˆ
    """
    def __init__(self, model_name="qwen-2.5-7b-instruct", device="cuda"):
        self.device = device
        self.model = AutoModelForCausalLM.from_pretrained(
            model_name,
            torch_dtype=torch.float16,
            device_map=device
        )
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
        
    def recognize(self, query, intent_list, temperature=0.1):
        """
        è¯†åˆ«æ··åˆæ„å›¾
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
            intent_list: æ‰€æœ‰å¯èƒ½çš„æ„å›¾åˆ—è¡¨
            temperature: ç”Ÿæˆæ¸©åº¦ï¼ˆè¶Šä½è¶Šç¡®å®šï¼‰
        
        Returns:
            list: è¯†åˆ«åˆ°çš„æ„å›¾åˆ—è¡¨
        """
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ„å›¾è¯†åˆ«ä¸“å®¶ã€‚è¯·åˆ†æç”¨æˆ·æŸ¥è¯¢ï¼Œè¯†åˆ«å…¶ä¸­åŒ…å«çš„æ‰€æœ‰æ„å›¾ã€‚

å¯èƒ½çš„æ„å›¾åˆ—è¡¨ï¼š
{', '.join(intent_list)}

ç”¨æˆ·æŸ¥è¯¢ï¼š{query}

è¯·ä»¥JSONæ ¼å¼è¾“å‡ºï¼ŒåŒ…å«æ‰€æœ‰è¯†åˆ«åˆ°çš„æ„å›¾ï¼š
{{"intents": ["æ„å›¾1", "æ„å›¾2", ...]}}

åªè¾“å‡ºJSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

        inputs = self.tokenizer(
            prompt, 
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=512
        ).to(self.device)
        
        with torch.no_grad():
            outputs = self.model.generate(
                **inputs,
                max_new_tokens=128,
                temperature=temperature,
                do_sample=temperature > 0,
                pad_token_id=self.tokenizer.pad_token_id
            )
        
        # è§£ç å“åº”
        response = self.tokenizer.decode(
            outputs[0][inputs['input_ids'].shape[1]:], 
            skip_special_tokens=True
        )
        
        # è§£æJSONï¼ˆå®¹é”™å¤„ç†ï¼‰
        try:
            # å°è¯•æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                result = json.loads(json_match.group())
                return result.get("intents", [])
            else:
                # å¦‚æœæ‰¾ä¸åˆ°JSONï¼Œå°è¯•ç›´æ¥è§£æ
                result = json.loads(response)
                return result.get("intents", [])
        except json.JSONDecodeError:
            # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
            print(f"Warning: Failed to parse LLM response: {response}")
            return []
```

#### ä¼˜åŠ¿ä¸å±€é™

**ä¼˜åŠ¿ï¼ˆ"ä»€ä¹ˆæ—¶å€™ç”¨"ï¼‰**ï¼š
- âœ… **é›¶æ ·æœ¬èƒ½åŠ›**ï¼šæ— éœ€è®­ç»ƒï¼Œç›´æ¥ä½¿ç”¨ï¼ˆé€‚åˆå¿«é€ŸåŸå‹ï¼‰
- âœ… **çµæ´»æ€§å¼º**ï¼šå¯ä»¥å¤„ç†å¼€æ”¾åŸŸæ„å›¾ï¼ˆä¸å—é¢„å®šä¹‰ç±»åˆ«é™åˆ¶ï¼‰
- âœ… **å°‘æ ·æœ¬å­¦ä¹ **ï¼šåªéœ€å°‘é‡ç¤ºä¾‹å³å¯é€‚é…ï¼ˆå‡ ä¸ªä¾‹å­å°±èƒ½å­¦ä¼šï¼‰

**å±€é™ï¼ˆ"ä»€ä¹ˆæ—¶å€™ä¸ç”¨"ï¼‰**ï¼š
- âŒ **å»¶è¿Ÿé«˜**ï¼šæ¨ç†æ—¶é—´ 500ms-2sï¼ˆä¸é€‚åˆå®æ—¶åœºæ™¯ï¼‰
- âŒ **æˆæœ¬é«˜**ï¼šéœ€è¦ GPU èµ„æºï¼ˆAPI è°ƒç”¨æˆæœ¬é«˜ï¼‰
- âŒ **å¯æ§æ€§å·®**ï¼šè¾“å‡ºæ ¼å¼å¯èƒ½ä¸ç¨³å®šï¼ˆJSON è§£æå¯èƒ½å¤±è´¥ï¼‰

#### æ··åˆæ–¹æ¡ˆï¼ˆæ¨èï¼‰

```python
# ä¸¤é˜¶æ®µæ¶æ„
def hybrid_intent_recognition(query):
    # é˜¶æ®µ1ï¼šå¿«é€Ÿåˆ†ç±»ï¼ˆBERTå¤šæ ‡ç­¾ï¼‰
    intents = bert_multi_intent_model(query)  # 20ms
    
    # é˜¶æ®µ2ï¼šå¤æ‚æƒ…å†µç”¨LLM
    if len(intents) == 0 or confidence < 0.7:
        intents = llm_intent_recognizer(query)  # 500ms
    
    return intents
```

---

### æ–¹æ¡ˆ4ï¸âƒ£ï¼šå›¾ç¥ç»ç½‘ç»œå¢å¼ºçš„å¤šæ„å›¾è¯†åˆ«ï¼ˆå‰æ²¿ç ”ç©¶ï¼‰

#### æ ¸å¿ƒæ€æƒ³ï¼šå»ºæ¨¡æ„å›¾ä¹‹é—´çš„ä¾èµ–å…³ç³»

```python
import torch.nn.functional as F
from torch_geometric.nn import GCNConv

class GraphIntentModel(nn.Module):
    """
    ä½¿ç”¨å›¾ç¥ç»ç½‘ç»œå»ºæ¨¡æ„å›¾ä¹‹é—´çš„å…³ç³»
    ä¾‹å¦‚ï¼šè®¢ç¥¨ â†’ æŸ¥è¯¢å¤©æ°”ï¼ˆç›¸å…³ï¼‰
         é€€æ¬¾ â†’ æŠ•è¯‰ï¼ˆç›¸å…³ï¼‰
    
    æ³¨æ„ï¼šéœ€è¦å®‰è£… torch-geometric: pip install torch-geometric
    """
    def __init__(self, num_intents, model_name="bert-base-chinese", dropout=0.1):
        super().__init__()
        self.encoder = AutoModel.from_pretrained(model_name)
        hidden_size = self.encoder.config.hidden_size
        self.num_intents = num_intents
        
        # æ„å›¾å…³ç³»å›¾ï¼ˆå¯å­¦ä¹ æˆ–é¢„å®šä¹‰ï¼‰
        # åˆå§‹åŒ–ä¸ºå•ä½çŸ©é˜µ + å°éšæœºå™ªå£°
        self.intent_graph = nn.Parameter(
            torch.eye(num_intents) + 0.1 * torch.randn(num_intents, num_intents)
        )
        
        # GCNå±‚ï¼ˆéœ€è¦å°†å›¾è½¬æ¢ä¸ºè¾¹ç´¢å¼•æ ¼å¼ï¼‰
        self.gcn = GCNConv(hidden_size, hidden_size)
        
        # åˆ†ç±»å™¨
        self.classifier = nn.Sequential(
            nn.Dropout(dropout),
            nn.Linear(hidden_size, 128),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(128, 1)
        )
        
    def _build_edge_index(self, device):
        """æ„å»ºå›¾ç¥ç»ç½‘ç»œçš„è¾¹ç´¢å¼•"""
        # å°†é‚»æ¥çŸ©é˜µè½¬æ¢ä¸ºè¾¹ç´¢å¼•
        edge_index = []
        for i in range(self.num_intents):
            for j in range(self.num_intents):
                if self.intent_graph[i, j] > 0.1:  # é˜ˆå€¼è¿‡æ»¤
                    edge_index.append([i, j])
        
        if len(edge_index) == 0:
            # å¦‚æœæ²¡æœ‰è¾¹ï¼Œåˆ›å»ºè‡ªç¯
            edge_index = [[i, i] for i in range(self.num_intents)]
        
        return torch.tensor(edge_index, dtype=torch.long).t().contiguous().to(device)
        
    def forward(self, input_ids, attention_mask):
        """
        Args:
            input_ids: [batch_size, seq_len]
            attention_mask: [batch_size, seq_len]
        
        Returns:
            logits: [batch_size, num_intents]
        """
        # æ–‡æœ¬ç¼–ç 
        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)
        text_emb = outputs.pooler_output  # [batch_size, hidden_size]
        
        # ä¸ºæ¯ä¸ªæ„å›¾åˆ›å»ºåˆå§‹èŠ‚ç‚¹ç‰¹å¾ï¼ˆä½¿ç”¨æ–‡æœ¬åµŒå…¥ï¼‰
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼šæ‰€æœ‰æ„å›¾å…±äº«æ–‡æœ¬åµŒå…¥
        intent_nodes = text_emb.unsqueeze(1).expand(-1, self.num_intents, -1)
        # [batch_size, num_intents, hidden_size]
        
        # æ„å»ºè¾¹ç´¢å¼•
        edge_index = self._build_edge_index(text_emb.device)
        
        # å¯¹æ¯ä¸ªæ ·æœ¬è¿›è¡Œå›¾å·ç§¯
        batch_size = text_emb.size(0)
        intent_embs_list = []
        for i in range(batch_size):
            node_features = intent_nodes[i]  # [num_intents, hidden_size]
            # GCN å‰å‘ä¼ æ’­
            intent_emb = self.gcn(node_features, edge_index)  # [num_intents, hidden_size]
            intent_embs_list.append(intent_emb)
        
        intent_embs = torch.stack(intent_embs_list, dim=0)  # [batch_size, num_intents, hidden_size]
        
        # æ¯ä¸ªæ„å›¾ç‹¬ç«‹åˆ†ç±»
        logits = self.classifier(intent_embs).squeeze(-1)  # [batch_size, num_intents]
        
        return logits
```

#### é€‚ç”¨åœºæ™¯

- âœ… æ„å›¾ä¹‹é—´å­˜åœ¨å¼ºç›¸å…³æ€§
- âœ… éœ€è¦åˆ©ç”¨æ„å›¾å…±ç°æ¨¡å¼
- âœ… æ•°æ®é‡å……è¶³ï¼ˆéœ€è¦å­¦ä¹ å›¾ç»“æ„ï¼‰

---

## ğŸ“Š æ–¹æ¡ˆå¯¹æ¯”ä¸é€‰å‹

| æ–¹æ¡ˆ | å‡†ç¡®ç‡ | å»¶è¿Ÿ | æˆæœ¬ | æ•°æ®éœ€æ±‚ | æ¨èåœºæ™¯ |
|------|--------|------|------|---------|---------|
| **Transformerå¤šæ ‡ç­¾** | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ | ä¸­ç­‰ | **ç”Ÿäº§ç¯å¢ƒé¦–é€‰** |
| **æ„å›¾æ„ŸçŸ¥æ³¨æ„åŠ›** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | ä¸­ç­‰ | é«˜ç²¾åº¦è¦æ±‚ |
| **LLMé›¶æ ·æœ¬** | â­â­â­ | â­â­ | â­â­ | æå°‘ | å¿«é€ŸåŸå‹ã€å¼€æ”¾åŸŸ |
| **å›¾ç¥ç»ç½‘ç»œ** | â­â­â­â­ | â­â­â­ | â­â­â­ | å¤§é‡ | æ„å›¾å…³ç³»å¤æ‚ |

### ğŸ¯ æ¨èæ–¹æ¡ˆï¼ˆç”Ÿäº§ç¯å¢ƒï¼Œ"ä¸‰æ­¥èµ°"ç­–ç•¥ï¼‰

**é˜¶æ®µ1ï¼šå¿«é€Ÿä¸Šçº¿ï¼ˆ"å…ˆè·‘èµ·æ¥"ï¼‰**
- ä½¿ç”¨ **Transformerå¤šæ ‡ç­¾åˆ†ç±»**ï¼ˆæ–¹æ¡ˆ1ï¼‰
- æ¨¡å‹ï¼šBERT/RoBERTa + å¤šæ ‡ç­¾åˆ†ç±»å¤´
- ä¼˜åŠ¿ï¼šå®ç°ç®€å•ã€æ€§èƒ½ç¨³å®šã€å»¶è¿Ÿä½ï¼ˆF1-macro 0.82-0.90ï¼‰
- **æ—¶é—´**ï¼š1-2 å‘¨å³å¯ä¸Šçº¿

**é˜¶æ®µ2ï¼šæ€§èƒ½ä¼˜åŒ–ï¼ˆ"è¿½æ±‚æè‡´"ï¼‰**
- å‡çº§åˆ° **æ„å›¾æ„ŸçŸ¥æ³¨æ„åŠ›**ï¼ˆæ–¹æ¡ˆ2ï¼‰
- æ€§èƒ½æå‡ **2-5% F1**ï¼ˆä» 0.85 åˆ° 0.87-0.90ï¼‰
- å¯è§£é‡Šæ€§å¢å¼ºï¼ˆçŸ¥é“æ¨¡å‹åœ¨çœ‹ä»€ä¹ˆï¼‰
- **æ—¶é—´**ï¼š2-3 å‘¨ä¼˜åŒ–

**é˜¶æ®µ3ï¼šå¤æ‚åœºæ™¯ï¼ˆ"å¤„ç†è¾¹ç•Œæƒ…å†µ"ï¼‰**
- å¼•å…¥ **LLMæ··åˆæ–¹æ¡ˆ**ï¼ˆæ–¹æ¡ˆ3ï¼‰
- å¤„ç†å¼€æ”¾åŸŸæ„å›¾ã€å°‘æ ·æœ¬åœºæ™¯
- **æ—¶é—´**ï¼šæŒ‰éœ€å¼•å…¥

---

## ğŸ”§ å®ç°ç»†èŠ‚ï¼ˆ"æ‰‹æŠŠæ‰‹"å®ç°ï¼‰

### 1. æ•°æ®å‡†å¤‡ï¼ˆ"æ•°æ®æ ¼å¼"ï¼‰

```python
# å¤šæ ‡ç­¾æ•°æ®æ ¼å¼
data = [
    {
        "query": "è®¢ä¸€å¼ æ˜å¤©å»åŒ—äº¬çš„æœºç¥¨",
        "intents": [1, 0, 0, 0, 0]  # åªæœ‰"è®¢ç¥¨"æ„å›¾
    },
    {
        "query": "è®¢æœºç¥¨å¹¶æŸ¥è¯¢å¤©æ°”",
        "intents": [1, 1, 0, 0, 0]  # "è®¢ç¥¨"å’Œ"æŸ¥è¯¢å¤©æ°”"
    },
    {
        "query": "é€€æ¬¾å¹¶æŠ•è¯‰å•†å®¶",
        "intents": [0, 0, 1, 1, 0]  # "é€€æ¬¾"å’Œ"æŠ•è¯‰"
    }
]

# æ„å›¾ç±»åˆ«æ˜ å°„
intent_map = {
    0: "è®¢ç¥¨",
    1: "æŸ¥è¯¢å¤©æ°”",
    2: "é€€æ¬¾",
    3: "æŠ•è¯‰",
    4: "å•†å“æµè§ˆ"
}
```

### 2. æŸå¤±å‡½æ•°é€‰æ‹©ï¼ˆ"é€‰å“ªä¸ª"ï¼‰

```python
# æ ‡å‡†å¤šæ ‡ç­¾æŸå¤±
criterion = nn.BCEWithLogitsLoss()

# å¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼ˆå¯é€‰ï¼‰
criterion = nn.BCEWithLogitsLoss(
    pos_weight=torch.tensor([2.0, 1.5, 3.0, 2.5, 1.0])  # æ­£æ ·æœ¬æƒé‡
)

# Focal Lossï¼ˆå¤„ç†éš¾æ ·æœ¬ï¼‰
import torch.nn.functional as F

class FocalLoss(nn.Module):
    """
    Focal Loss for multi-label classification
    ç”¨äºå¤„ç†ç±»åˆ«ä¸å¹³è¡¡å’Œéš¾æ ·æœ¬
    
    Paper: Focal Loss for Dense Object Detection (ICCV 2017)
    """
    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):
        """
        Args:
            alpha: å¹³è¡¡å› å­ï¼Œç”¨äºå¹³è¡¡æ­£è´Ÿæ ·æœ¬
            gamma: èšç„¦å‚æ•°ï¼Œgammaè¶Šå¤§ï¼Œå¯¹éš¾æ ·æœ¬çš„å…³æ³¨åº¦è¶Šé«˜
            reduction: 'mean' æˆ– 'sum'
        """
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction
        
    def forward(self, logits, targets):
        """
        Args:
            logits: [batch_size, num_classes] æ¨¡å‹è¾“å‡ºï¼ˆæœªç»è¿‡sigmoidï¼‰
            targets: [batch_size, num_classes] çœŸå®æ ‡ç­¾ï¼ˆ0æˆ–1ï¼‰
        
        Returns:
            loss: æ ‡é‡æŸå¤±å€¼
        """
        # è®¡ç®—BCEæŸå¤±ï¼ˆæ¯ä¸ªæ ·æœ¬æ¯ä¸ªç±»åˆ«ï¼‰
        bce = F.binary_cross_entropy_with_logits(
            logits, targets, reduction='none'
        )  # [batch_size, num_classes]
        
        # è®¡ç®—æ¦‚ç‡
        pt = torch.exp(-bce)  # pt = p if target=1, else 1-p
        
        # Focal Losså…¬å¼
        focal_loss = self.alpha * (1 - pt) ** self.gamma * bce
        
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss

# ä½¿ç”¨ç¤ºä¾‹
# criterion = FocalLoss(alpha=0.25, gamma=2.0)
```

### 3. è¯„ä¼°æŒ‡æ ‡ï¼ˆ"æ€ä¹ˆè¯„ä¼°"ï¼‰

```python
from sklearn.metrics import (
    f1_score, hamming_loss, accuracy_score,
    precision_score, recall_score, classification_report
)
import numpy as np

def evaluate_multi_label(y_true, y_pred, y_probs=None):
    """
    å¤šæ ‡ç­¾åˆ†ç±»è¯„ä¼°æŒ‡æ ‡
    
    Args:
        y_true: çœŸå®æ ‡ç­¾ [n_samples, n_classes] æˆ– [n_samples] (å¦‚æœæ˜¯åˆ—è¡¨)
        y_pred: é¢„æµ‹æ ‡ç­¾ [n_samples, n_classes] æˆ– [n_samples] (å¦‚æœæ˜¯åˆ—è¡¨)
        y_probs: é¢„æµ‹æ¦‚ç‡ [n_samples, n_classes] (å¯é€‰ï¼Œç”¨äºè®¡ç®—AUC)
    
    Returns:
        metrics: è¯„ä¼°æŒ‡æ ‡å­—å…¸
    """
    # ç¡®ä¿æ˜¯ numpy æ•°ç»„
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    
    # å¦‚æœæ˜¯åˆ—è¡¨æ ¼å¼ï¼Œè½¬æ¢ä¸ºå¤šæ ‡ç­¾æ ¼å¼
    if y_true.ndim == 1:
        # å‡è®¾æ˜¯åˆ—è¡¨çš„åˆ—è¡¨ï¼Œéœ€è¦è½¬æ¢ä¸ºäºŒè¿›åˆ¶çŸ©é˜µ
        # è¿™é‡Œå‡è®¾å·²ç»è½¬æ¢å¥½äº†
        pass
    
    # 1. F1-macroï¼šæ¯ä¸ªç±»åˆ«å•ç‹¬è®¡ç®—F1ï¼Œç„¶åå¹³å‡ï¼ˆè€ƒè™‘ç±»åˆ«ä¸å¹³è¡¡ï¼‰
    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)
    
    # 2. F1-microï¼šå…¨å±€è®¡ç®—F1ï¼ˆæ‰€æœ‰æ ·æœ¬å’Œç±»åˆ«ä¸€èµ·è®¡ç®—ï¼‰
    f1_micro = f1_score(y_true, y_pred, average='micro', zero_division=0)
    
    # 3. F1-weightedï¼šæŒ‰ç±»åˆ«æ ·æœ¬æ•°åŠ æƒå¹³å‡
    f1_weighted = f1_score(y_true, y_pred, average='weighted', zero_division=0)
    
    # 4. Hamming Lossï¼šé”™è¯¯æ ‡ç­¾çš„æ¯”ä¾‹ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
    hamming = hamming_loss(y_true, y_pred)
    
    # 5. Exact Match (Subset Accuracy)ï¼šå®Œå…¨åŒ¹é…çš„æ¯”ä¾‹
    exact_match = accuracy_score(y_true, y_pred)
    
    # 6. Precision/Recall (macro)
    precision_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)
    recall_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)
    
    # 7. Precision/Recall (micro)
    precision_micro = precision_score(y_true, y_pred, average='micro', zero_division=0)
    recall_micro = recall_score(y_true, y_pred, average='micro', zero_division=0)
    
    metrics = {
        'f1_macro': f1_macro,
        'f1_micro': f1_micro,
        'f1_weighted': f1_weighted,
        'precision_macro': precision_macro,
        'recall_macro': recall_macro,
        'precision_micro': precision_micro,
        'recall_micro': recall_micro,
        'hamming_loss': hamming,
        'exact_match': exact_match,
    }
    
    # 8. å¦‚æœæœ‰æ¦‚ç‡ï¼Œè®¡ç®—æ¯ä¸ªç±»åˆ«çš„AUC
    if y_probs is not None:
        from sklearn.metrics import roc_auc_score
        try:
            auc_macro = roc_auc_score(y_true, y_probs, average='macro')
            auc_micro = roc_auc_score(y_true, y_probs, average='micro')
            metrics['auc_macro'] = auc_macro
            metrics['auc_micro'] = auc_micro
        except ValueError:
            # æŸäº›ç±»åˆ«å¯èƒ½æ²¡æœ‰æ­£æ ·æœ¬
            pass
    
    return metrics

def print_classification_report(y_true, y_pred, intent_names):
    """
    æ‰“å°è¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Šï¼ˆæ¯ä¸ªç±»åˆ«çš„æŒ‡æ ‡ï¼‰
    """
    report = classification_report(
        y_true, y_pred,
        target_names=intent_names,
        zero_division=0
    )
    print(report)
```

### 4. é˜ˆå€¼ä¼˜åŒ–ï¼ˆ"è°ƒå‚æŠ€å·§"ï¼‰

```python
def find_optimal_threshold(y_true, y_pred_probs, metric='f1_macro', threshold_range=(0.1, 0.9), step=0.01):
    """
    å¯»æ‰¾æœ€ä¼˜åˆ†ç±»é˜ˆå€¼
    
    Args:
        y_true: çœŸå®æ ‡ç­¾ [n_samples, n_classes]
        y_pred_probs: é¢„æµ‹æ¦‚ç‡ [n_samples, n_classes]
        metric: ä¼˜åŒ–æŒ‡æ ‡ ('f1_macro', 'f1_micro', 'exact_match')
        threshold_range: é˜ˆå€¼æœç´¢èŒƒå›´
        step: æœç´¢æ­¥é•¿
    
    Returns:
        best_threshold: æœ€ä¼˜é˜ˆå€¼
        best_score: æœ€ä¼˜åˆ†æ•°
        threshold_scores: æ‰€æœ‰é˜ˆå€¼å¯¹åº”çš„åˆ†æ•°
    """
    best_threshold = 0.5
    best_score = 0
    threshold_scores = []
    
    for threshold in np.arange(threshold_range[0], threshold_range[1], step):
        y_pred = (y_pred_probs > threshold).astype(int)
        
        if metric == 'f1_macro':
            score = f1_score(y_true, y_pred, average='macro', zero_division=0)
        elif metric == 'f1_micro':
            score = f1_score(y_true, y_pred, average='micro', zero_division=0)
        elif metric == 'exact_match':
            score = accuracy_score(y_true, y_pred)
        else:
            raise ValueError(f"Unknown metric: {metric}")
        
        threshold_scores.append((threshold, score))
        
        if score > best_score:
            best_score = score
            best_threshold = threshold
    
    return best_threshold, best_score, threshold_scores

def find_per_class_threshold(y_true, y_pred_probs):
    """
    ä¸ºæ¯ä¸ªç±»åˆ«å¯»æ‰¾æœ€ä¼˜é˜ˆå€¼ï¼ˆæ›´ç²¾ç»†çš„ä¼˜åŒ–ï¼‰
    
    Returns:
        thresholds: [n_classes] æ¯ä¸ªç±»åˆ«çš„æœ€ä¼˜é˜ˆå€¼
    """
    n_classes = y_pred_probs.shape[1]
    thresholds = []
    
    for i in range(n_classes):
        y_true_class = y_true[:, i]
        y_pred_class = y_pred_probs[:, i]
        
        best_threshold, best_f1, _ = find_optimal_threshold(
            y_true_class.reshape(-1, 1),
            y_pred_class.reshape(-1, 1),
            metric='f1_macro'
        )
        thresholds.append(best_threshold)
    
    return np.array(thresholds)
```

### 5. å®Œæ•´è®­ç»ƒç¤ºä¾‹

```python
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from transformers import AutoTokenizer, get_linear_schedule_with_warmup
from tqdm import tqdm

class MultiIntentDataset(Dataset):
    """å¤šæ ‡ç­¾æ„å›¾è¯†åˆ«æ•°æ®é›†"""
    def __init__(self, texts, labels, tokenizer, max_length=128):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length
    
    def __len__(self):
        return len(self.texts)
    
    def __getitem__(self, idx):
        text = str(self.texts[idx])
        label = self.labels[idx]
        
        # Tokenize
        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )
        
        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.FloatTensor(label)
        }

def train_multi_intent_model(
    model, train_loader, val_loader, 
    num_epochs=10, learning_rate=2e-5,
    device='cuda'
):
    """
    è®­ç»ƒå¤šæ ‡ç­¾æ„å›¾è¯†åˆ«æ¨¡å‹
    """
    model.to(device)
    
    # ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦å™¨
    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=learning_rate,
        weight_decay=0.01
    )
    
    total_steps = len(train_loader) * num_epochs
    scheduler = get_linear_schedule_with_warmup(
        optimizer,
        num_warmup_steps=total_steps // 10,
        num_training_steps=total_steps
    )
    
    # æŸå¤±å‡½æ•°ï¼ˆå¸¦ç±»åˆ«æƒé‡ï¼‰
    criterion = nn.BCEWithLogitsLoss()
    
    best_f1 = 0
    
    for epoch in range(num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0
        
        for batch in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}"):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)
            
            # å‰å‘ä¼ æ’­
            logits = model(input_ids, attention_mask)
            loss = criterion(logits, labels)
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            scheduler.step()
            
            train_loss += loss.item()
        
        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0
        all_preds = []
        all_labels = []
        
        with torch.no_grad():
            for batch in val_loader:
                input_ids = batch['input_ids'].to(device)
                attention_mask = batch['attention_mask'].to(device)
                labels = batch['labels'].to(device)
                
                logits = model(input_ids, attention_mask)
                loss = criterion(logits, labels)
                val_loss += loss.item()
                
                # é¢„æµ‹
                probs = torch.sigmoid(logits)
                preds = (probs > 0.5).int().cpu().numpy()
                
                all_preds.append(preds)
                all_labels.append(labels.cpu().numpy())
        
        # è®¡ç®—æŒ‡æ ‡
        all_preds = np.vstack(all_preds)
        all_labels = np.vstack(all_labels)
        
        metrics = evaluate_multi_label(all_labels, all_preds)
        
        print(f"\nEpoch {epoch+1}/{num_epochs}")
        print(f"Train Loss: {train_loss/len(train_loader):.4f}")
        print(f"Val Loss: {val_loss/len(val_loader):.4f}")
        print(f"F1-Macro: {metrics['f1_macro']:.4f}")
        print(f"F1-Micro: {metrics['f1_micro']:.4f}")
        print(f"Exact Match: {metrics['exact_match']:.4f}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if metrics['f1_macro'] > best_f1:
            best_f1 = metrics['f1_macro']
            torch.save(model.state_dict(), 'best_model.pth')
            print(f"âœ“ Saved best model (F1-Macro: {best_f1:.4f})")
    
    return model

# ä½¿ç”¨ç¤ºä¾‹
# tokenizer = AutoTokenizer.from_pretrained("bert-base-chinese")
# train_dataset = MultiIntentDataset(train_texts, train_labels, tokenizer)
# val_dataset = MultiIntentDataset(val_texts, val_labels, tokenizer)
# 
# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
# 
# model = MultiIntentTransformer(num_intents=10, model_name="bert-base-chinese")
# trained_model = train_multi_intent_model(model, train_loader, val_loader)
```

---

## ğŸš€ å®æˆ˜æ¡ˆä¾‹ï¼ˆ"çœŸå®åœºæ™¯"ï¼‰

### æ¡ˆä¾‹1ï¼šæ™ºèƒ½å®¢æœç³»ç»Ÿï¼ˆ"10ä¸ªæ„å›¾ç±»åˆ«"ï¼‰

```python
import torch
import numpy as np
from transformers import AutoTokenizer

class CustomerServiceIntentRecognizer:
    """
    æ™ºèƒ½å®¢æœæ··åˆæ„å›¾è¯†åˆ«
    
    å®Œæ•´å®ç°ç¤ºä¾‹ï¼ŒåŒ…å«æ¨¡å‹åŠ è½½ã€æ¨ç†å’Œç»“æœå¤„ç†
    """
    def __init__(self, model_path=None, model_name="bert-base-chinese", threshold=0.5):
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.threshold = threshold
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = MultiIntentTransformer(
            num_intents=10,
            model_name=model_name
        )
        
        if model_path:
            # åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹æƒé‡
            self.model.load_state_dict(torch.load(model_path, map_location=self.device))
        
        self.model.to(self.device)
        self.model.eval()
        
        # åˆå§‹åŒ– tokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        
        # æ„å›¾æ˜ å°„
        self.intent_map = {
            0: "å’¨è¯¢",
            1: "æŠ•è¯‰",
            2: "é€€æ¬¾",
            3: "æ¢è´§",
            4: "æŸ¥è¯¢è®¢å•",
            5: "ä¿®æ”¹ä¿¡æ¯",
            6: "å–æ¶ˆè®¢å•",
            7: "è¯„ä»·",
            8: "è”ç³»å®¢æœ",
            9: "å…¶ä»–"
        }
    
    def recognize(self, query, return_probs=False):
        """
        è¯†åˆ«æ··åˆæ„å›¾
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢æ–‡æœ¬
            return_probs: æ˜¯å¦è¿”å›æ¦‚ç‡å€¼
        
        Returns:
            intents: è¯†åˆ«åˆ°çš„æ„å›¾åˆ—è¡¨
            probs (å¯é€‰): æ¯ä¸ªæ„å›¾çš„æ¦‚ç‡
        """
        # Tokenize
        inputs = self.tokenizer(
            query,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=128
        ).to(self.device)
        
        # é¢„æµ‹
        with torch.no_grad():
            logits = self.model(
                input_ids=inputs["input_ids"],
                attention_mask=inputs["attention_mask"]
            )
            probs = torch.sigmoid(logits).cpu().numpy()[0]
        
        # é˜ˆå€¼è¿‡æ»¤
        predictions = (probs > self.threshold).astype(int)
        
        # è¿”å›è¯†åˆ«çš„æ„å›¾
        intents = [
            self.intent_map[i] 
            for i, pred in enumerate(predictions) 
            if pred == 1
        ]
        
        if return_probs:
            intent_probs = {
                self.intent_map[i]: float(probs[i])
                for i in range(len(probs))
            }
            return intents, intent_probs
        else:
            return intents

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    recognizer = CustomerServiceIntentRecognizer(
        model_path="best_model.pth",  # åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹ï¼Œæˆ–ä½¿ç”¨ None ä»å¤´è®­ç»ƒ
        threshold=0.5
    )
    
    query = "æˆ‘è¦é€€æ¬¾ï¼Œè¿˜è¦æŠ•è¯‰è¿™ä¸ªå•†å®¶"
    intents, probs = recognizer.recognize(query, return_probs=True)
    
    print(f"æŸ¥è¯¢: {query}")
    print(f"è¯†åˆ«æ„å›¾: {intents}")
    print(f"å„æ„å›¾æ¦‚ç‡: {probs}")
    # è¾“å‡º: 
    # æŸ¥è¯¢: æˆ‘è¦é€€æ¬¾ï¼Œè¿˜è¦æŠ•è¯‰è¿™ä¸ªå•†å®¶
    # è¯†åˆ«æ„å›¾: ['é€€æ¬¾', 'æŠ•è¯‰']
    # å„æ„å›¾æ¦‚ç‡: {'å’¨è¯¢': 0.12, 'æŠ•è¯‰': 0.89, 'é€€æ¬¾': 0.92, ...}
```

### æ¡ˆä¾‹2ï¼šå¯¹è¯ç³»ç»Ÿæ„å›¾ç†è§£ï¼ˆ"å¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡"ï¼‰

```python
class DialogIntentRecognizer:
    """
    å¯¹è¯ç³»ç»Ÿä¸­çš„æ··åˆæ„å›¾è¯†åˆ«
    æ”¯æŒå¤šè½®å¯¹è¯ä¸Šä¸‹æ–‡
    """
    def __init__(self):
        self.model = IntentAwareModel(
            num_intents=15,
            model_name="roberta-base"
        )
        self.context_window = 5  # ä¿ç•™æœ€è¿‘5è½®å¯¹è¯
    
    def recognize(self, current_query, dialog_history):
        # æ„å»ºä¸Šä¸‹æ–‡
        context = " ".join([
            f"ç”¨æˆ·: {turn['user']} åŠ©æ‰‹: {turn['assistant']}"
            for turn in dialog_history[-self.context_window:]
        ])
        
        # å½“å‰æŸ¥è¯¢ + ä¸Šä¸‹æ–‡
        full_query = f"{context} ç”¨æˆ·: {current_query}"
        
        # è¯†åˆ«æ„å›¾
        intents = self.model(full_query)
        
        return intents
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–æŠ€å·§ï¼ˆ"æå‡æ€§èƒ½"ï¼‰

### 1. æ•°æ®å¢å¼ºï¼ˆ"æ•°æ®ä¸å¤Ÿï¼Œå¢å¼ºæ¥å‡‘"ï¼‰

```python
import random
import copy

def augment_multi_intent_data(query, intents, intent_templates=None):
    """
    é€šè¿‡ç»„åˆä¸åŒæ„å›¾çš„æŸ¥è¯¢æ¥å¢å¼ºæ•°æ®
    
    Args:
        query: åŸå§‹æŸ¥è¯¢
        intents: æ„å›¾åˆ—è¡¨
        intent_templates: æ„å›¾æ¨¡æ¿å­—å…¸ï¼Œæ ¼å¼ï¼š{intent: [template1, template2, ...]}
    
    Returns:
        augmented: [(query, intents), ...] å¢å¼ºåçš„æ•°æ®åˆ—è¡¨
    """
    import random
    import copy
    
    augmented = []
    
    # æ–¹æ³•1ï¼šæ„å›¾ç»„åˆï¼ˆæ‰“ä¹±æ„å›¾é¡ºåºï¼‰
    if len(intents) > 1:
        shuffled_intents = copy.copy(intents)
        random.shuffle(shuffled_intents)  # æ³¨æ„ï¼šshuffle æ˜¯åŸåœ°æ“ä½œ
        
        # å¦‚æœæœ‰æ¨¡æ¿ï¼Œç”Ÿæˆæ–°æŸ¥è¯¢
        if intent_templates:
            new_query = generate_query_from_intents(shuffled_intents, intent_templates)
        else:
            # ç®€å•æ‹¼æ¥
            new_query = " ".join([f"[{intent}]" for intent in shuffled_intents])
        
        augmented.append((new_query, shuffled_intents))
    
    # æ–¹æ³•2ï¼šåŒä¹‰è¯æ›¿æ¢
    # æ³¨æ„ï¼šéœ€è¦å®ç° get_synonyms å‡½æ•°æˆ–ä½¿ç”¨åŒä¹‰è¯åº“
    # from nltk.corpus import wordnet
    # synonyms = get_synonyms_from_wordnet(query)
    
    # æ–¹æ³•3ï¼šå›è¯‘ï¼ˆå¦‚æœæœ‰ç¿»è¯‘æ¨¡å‹ï¼‰
    # translated = translate_to_english(query)
    # back_translated = translate_to_chinese(translated)
    # augmented.append((back_translated, intents))
    
    # æ–¹æ³•4ï¼šéšæœºåˆ é™¤/æ’å…¥è¯ï¼ˆä¿æŒæ„å›¾ä¸å˜ï¼‰
    words = query.split()
    if len(words) > 3:
        # éšæœºåˆ é™¤ä¸€ä¸ªè¯
        deleted_words = copy.copy(words)
        deleted_words.pop(random.randint(0, len(deleted_words) - 1))
        augmented.append((" ".join(deleted_words), intents))
    
    return augmented

def generate_query_from_intents(intents, intent_templates):
    """
    æ ¹æ®æ„å›¾åˆ—è¡¨å’Œæ¨¡æ¿ç”ŸæˆæŸ¥è¯¢
    
    Args:
        intents: æ„å›¾åˆ—è¡¨
        intent_templates: æ„å›¾æ¨¡æ¿å­—å…¸
    
    Returns:
        query: ç”Ÿæˆçš„æŸ¥è¯¢
    """
    import random
    
    query_parts = []
    for intent in intents:
        if intent in intent_templates:
            template = random.choice(intent_templates[intent])
            query_parts.append(template)
        else:
            query_parts.append(f"[{intent}]")
    
    # ä½¿ç”¨è¿æ¥è¯ç»„åˆ
    connectors = ["å¹¶", "åŒæ—¶", "è¿˜è¦", "é¡ºä¾¿"]
    if len(query_parts) > 1:
        connector = random.choice(connectors)
        return connector.join(query_parts)
    else:
        return query_parts[0]
```

### 2. ç±»åˆ«ä¸å¹³è¡¡å¤„ç†ï¼ˆ"å¸¸è§é—®é¢˜"ï¼‰

```python
import torch
import torch.nn as nn
from sklearn.utils.class_weight import compute_class_weight
# from imblearn.over_sampling import RandomOverSampler  # å¤šæ ‡ç­¾åœºæ™¯éœ€è°¨æ…ä½¿ç”¨
# from imblearn.combine import SMOTETomek  # å¤šæ ‡ç­¾åœºæ™¯éœ€è°¨æ…ä½¿ç”¨

def compute_class_weights(y_train):
    """
    è®¡ç®—ç±»åˆ«æƒé‡ï¼ˆç”¨äºåŠ æƒæŸå¤±ï¼‰
    
    Args:
        y_train: è®­ç»ƒæ ‡ç­¾ [n_samples, n_classes]
    
    Returns:
        pos_weights: æ­£æ ·æœ¬æƒé‡ [n_classes]
    """
    n_classes = y_train.shape[1]
    pos_weights = []
    
    for i in range(n_classes):
        # è®¡ç®—æ­£è´Ÿæ ·æœ¬æ¯”ä¾‹
        pos_count = y_train[:, i].sum()
        neg_count = len(y_train) - pos_count
        
        if pos_count > 0:
            # æƒé‡ = è´Ÿæ ·æœ¬æ•° / æ­£æ ·æœ¬æ•°
            weight = neg_count / pos_count
        else:
            weight = 1.0
        
        pos_weights.append(weight)
    
    return torch.tensor(pos_weights, dtype=torch.float32)

# æ–¹æ³•1ï¼šåŠ æƒæŸå¤±ï¼ˆæ¨èï¼‰
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
pos_weights = compute_class_weights(y_train)
criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights.to(device))

# æ–¹æ³•2ï¼šè¿‡é‡‡æ ·å°‘æ•°ç±»ï¼ˆæ³¨æ„ï¼šå¤šæ ‡ç­¾éœ€è¦ç‰¹æ®Šå¤„ç†ï¼‰
# å¯¹äºå¤šæ ‡ç­¾ï¼Œå¯ä»¥ä½¿ç”¨ ML-ROS (Multi-Label Random Over-Sampling)
# æ³¨æ„ï¼šå¤šæ ‡ç­¾è¿‡é‡‡æ ·éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œå¯èƒ½éœ€è¦ä½¿ç”¨ä¸“é—¨çš„å¤šæ ‡ç­¾è¿‡é‡‡æ ·æ–¹æ³•
# from imblearn.over_sampling import RandomOverSampler  # å¤šæ ‡ç­¾åœºæ™¯éœ€è°¨æ…ä½¿ç”¨

# æ–¹æ³•3ï¼šFocal Lossï¼ˆå¤„ç†éš¾æ ·æœ¬ï¼‰
criterion = FocalLoss(alpha=0.25, gamma=2.0)

# æ–¹æ³•4ï¼šç»„åˆé‡‡æ ·ï¼ˆSMOTE + Tomekï¼‰
# smote_tomek = SMOTETomek(random_state=42)
# X_resampled, y_resampled = smote_tomek.fit_resample(X, y)

# æ–¹æ³•5ï¼šä»£ä»·æ•æ„Ÿå­¦ä¹ ï¼ˆåœ¨æŸå¤±å‡½æ•°ä¸­ä½“ç°ï¼‰
class WeightedBCELoss(nn.Module):
    def __init__(self, pos_weight, neg_weight=None):
        super().__init__()
        self.pos_weight = pos_weight
        self.neg_weight = neg_weight if neg_weight is not None else torch.ones_like(pos_weight)
    
    def forward(self, logits, targets):
        # åˆ†åˆ«è®¡ç®—æ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬çš„æŸå¤±
        pos_loss = -self.pos_weight * targets * torch.log(torch.sigmoid(logits) + 1e-8)
        neg_loss = -self.neg_weight * (1 - targets) * torch.log(1 - torch.sigmoid(logits) + 1e-8)
        return (pos_loss + neg_loss).mean()
```

### 3. æ¨¡å‹é›†æˆï¼ˆ"ä¸‰ä¸ªè‡­çš®åŒ é¡¶ä¸ªè¯¸è‘›äº®"ï¼‰

```python
class EnsembleMultiIntentModel:
    """
    é›†æˆå¤šä¸ªæ¨¡å‹æå‡æ€§èƒ½
    
    ç­–ç•¥ï¼š
    1. å¹³å‡æ¦‚ç‡ï¼ˆç®€å•å¹³å‡ï¼‰
    2. åŠ æƒå¹³å‡ï¼ˆæ ¹æ®éªŒè¯é›†æ€§èƒ½åŠ æƒï¼‰
    3. æŠ•ç¥¨ï¼ˆç¡¬æŠ•ç¥¨æˆ–è½¯æŠ•ç¥¨ï¼‰
    """
    def __init__(self, models, weights=None, method='average'):
        """
        Args:
            models: æ¨¡å‹åˆ—è¡¨
            weights: æ¨¡å‹æƒé‡ï¼ˆå¦‚æœä¸ºNoneï¼Œåˆ™ç­‰æƒé‡ï¼‰
            method: é›†æˆæ–¹æ³• ('average', 'weighted', 'voting')
        """
        self.models = models
        self.method = method
        
        if weights is None:
            self.weights = [1.0 / len(models)] * len(models)
        else:
            assert len(weights) == len(models), "æƒé‡æ•°é‡å¿…é¡»ç­‰äºæ¨¡å‹æ•°é‡"
            # å½’ä¸€åŒ–æƒé‡
            total = sum(weights)
            self.weights = [w / total for w in weights]
    
    def predict(self, input_ids, attention_mask, return_probs=False):
        """
        é›†æˆé¢„æµ‹
        
        Args:
            input_ids: [batch_size, seq_len]
            attention_mask: [batch_size, seq_len]
            return_probs: æ˜¯å¦è¿”å›æ¦‚ç‡
        
        Returns:
            logits æˆ– (logits, probs)
        """
        predictions = []
        
        for model in self.models:
            model.eval()
            with torch.no_grad():
                logits = model(input_ids, attention_mask)
                predictions.append(logits)
        
        # é›†æˆç­–ç•¥
        if self.method == 'average':
            # ç®€å•å¹³å‡
            ensemble_logits = torch.mean(torch.stack(predictions), dim=0)
        elif self.method == 'weighted':
            # åŠ æƒå¹³å‡
            weighted_preds = [
                pred * weight 
                for pred, weight in zip(predictions, self.weights)
            ]
            ensemble_logits = torch.sum(torch.stack(weighted_preds), dim=0)
        elif self.method == 'voting':
            # è½¯æŠ•ç¥¨ï¼ˆå¹³å‡æ¦‚ç‡åå–é˜ˆå€¼ï¼‰
            probs = [torch.sigmoid(pred) for pred in predictions]
            avg_probs = torch.mean(torch.stack(probs), dim=0)
            ensemble_logits = torch.log(avg_probs / (1 - avg_probs + 1e-8))
        else:
            raise ValueError(f"Unknown method: {self.method}")
        
        if return_probs:
            probs = torch.sigmoid(ensemble_logits)
            return ensemble_logits, probs
        else:
            return ensemble_logits

# ä½¿ç”¨ç¤ºä¾‹
# models = [
#     MultiIntentTransformer(num_intents, "bert-base-chinese"),
#     MultiIntentTransformer(num_intents, "roberta-base"),
#     IntentAwareModel(num_intents, "bert-base-chinese")
# ]
# ensemble = EnsembleMultiIntentModel(
#     models=models,
#     weights=[0.4, 0.3, 0.3],  # æ ¹æ®éªŒè¯é›†æ€§èƒ½è®¾ç½®
#     method='weighted'
# )
```

---

## ğŸ¯ æ€»ç»“ï¼ˆ"æ ¸å¿ƒè¦ç‚¹"ï¼‰

### æ ¸å¿ƒè¦ç‚¹ï¼ˆ"å¿…è®°"ï¼‰

1. **æ··åˆæ„å›¾è¯†åˆ« = å¤šæ ‡ç­¾åˆ†ç±»é—®é¢˜**
   - âœ… å¿…é¡»ä½¿ç”¨å¤šæ ‡ç­¾åˆ†ç±»æ¡†æ¶ï¼ˆä¸èƒ½ç”¨å•æ„å›¾åˆ†ç±»æ–¹æ³•ï¼‰
   - âœ… æ¯ä¸ªæ„å›¾æ˜¯ç‹¬ç«‹æ ‡ç­¾ï¼Œå¯ä»¥å…±å­˜ï¼ˆä¸æ˜¯äº’æ–¥çš„ï¼‰

2. **SOTA æ–¹æ¡ˆæ¨èï¼ˆ"é€‰å‹æŒ‡å—"ï¼‰**
   - **ç”Ÿäº§ç¯å¢ƒé¦–é€‰**ï¼šTransformer + å¤šæ ‡ç­¾åˆ†ç±»å¤´ï¼ˆBERT/RoBERTaï¼‰ï¼ŒF1-macro 0.82-0.90
   - **é«˜ç²¾åº¦éœ€æ±‚**ï¼šæ„å›¾æ„ŸçŸ¥æ³¨æ„åŠ›æœºåˆ¶ï¼Œæ€§èƒ½æå‡ 2-5% F1
   - **å¿«é€ŸåŸå‹**ï¼šLLM é›¶æ ·æœ¬æ–¹æ¡ˆï¼Œæ— éœ€è®­ç»ƒ
   - **å¤æ‚å…³ç³»**ï¼šå›¾ç¥ç»ç½‘ç»œï¼Œé€‚åˆæ„å›¾å…³ç³»å¤æ‚çš„åœºæ™¯

3. **å…³é”®æŠ€æœ¯ï¼ˆ"å·¥å…·ç®±"ï¼‰**
   - **æŸå¤±å‡½æ•°**ï¼šBCEWithLogitsLossï¼ˆæ ‡å‡†ï¼‰ / Focal Lossï¼ˆå¤„ç†éš¾æ ·æœ¬ï¼‰
   - **è¯„ä¼°æŒ‡æ ‡**ï¼šF1-macroï¼ˆç±»åˆ«å¹³è¡¡ï¼‰, F1-microï¼ˆå…¨å±€ï¼‰, Hamming Lossï¼ˆé”™è¯¯ç‡ï¼‰
   - **é˜ˆå€¼ä¼˜åŒ–**ï¼šåŠ¨æ€è°ƒæ•´åˆ†ç±»é˜ˆå€¼ï¼ˆ0.3-0.7 èŒƒå›´æœç´¢ï¼‰
   - **æ•°æ®å¢å¼º**ï¼šæ„å›¾ç»„åˆã€åŒä¹‰è¯æ›¿æ¢ã€å›è¯‘

4. **å·¥ç¨‹å®è·µï¼ˆ"é¿å‘æŒ‡å—"ï¼‰**
   - âœ… å¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼ˆåŠ æƒæŸå¤±ã€è¿‡é‡‡æ ·ã€Focal Lossï¼‰
   - âœ… ä¼˜åŒ–æ¨ç†å»¶è¿Ÿï¼ˆæ¨¡å‹å‹ç¼©ã€é‡åŒ–ã€ç¼“å­˜ï¼‰
   - âœ… æ¨¡å‹é›†æˆæå‡æ€§èƒ½ï¼ˆ3-5 ä¸ªæ¨¡å‹é›†æˆï¼ŒF1 æå‡ 1-3%ï¼‰
   - âœ… å¯è§£é‡Šæ€§åˆ†æï¼ˆå¯è§†åŒ–æ³¨æ„åŠ›æƒé‡ï¼‰

### æœªæ¥æ–¹å‘ï¼ˆ"è¶‹åŠ¿é¢„æµ‹"ï¼‰

- ğŸ”® **LLM åŸç”Ÿæ”¯æŒ**ï¼šéšç€ LLM èƒ½åŠ›å¢å¼ºï¼Œé›¶æ ·æœ¬æ··åˆæ„å›¾è¯†åˆ«å°†æˆä¸ºä¸»æµï¼ˆæ— éœ€è®­ç»ƒï¼Œç›´æ¥ä½¿ç”¨ï¼‰
- ğŸ”® **å¤šæ¨¡æ€èåˆ**ï¼šç»“åˆè¯­éŸ³ã€å›¾åƒç­‰å¤šæ¨¡æ€ä¿¡æ¯ï¼ˆä¸ä»…çœ‹æ–‡æœ¬ï¼Œè¿˜å¬å£°éŸ³ã€çœ‹å›¾ç‰‡ï¼‰
- ğŸ”® **åœ¨çº¿å­¦ä¹ **ï¼šæŒç»­å­¦ä¹ æ–°æ„å›¾ï¼Œæ— éœ€é‡æ–°è®­ç»ƒï¼ˆæ¨¡å‹è‡ªåŠ¨é€‚åº”æ–°æ„å›¾ï¼‰
- ğŸ”® **ä¸ªæ€§åŒ–æ„å›¾**ï¼šæ ¹æ®ç”¨æˆ·ç”»åƒä¸ªæ€§åŒ–æ„å›¾è¯†åˆ«ï¼ˆä¸åŒç”¨æˆ·ï¼Œä¸åŒç†è§£ï¼‰

---

## ğŸš€ å¿«é€Ÿå¼€å§‹æŒ‡å—

### æ­¥éª¤1ï¼šå®‰è£…ä¾èµ–

```bash
pip install torch transformers scikit-learn
pip install pandas numpy tqdm
# å¯é€‰ï¼šç”¨äºå›¾ç¥ç»ç½‘ç»œ
pip install torch-geometric
# å¯é€‰ï¼šç”¨äºæ•°æ®å¢å¼º
pip install imbalanced-learn
```

### æ­¥éª¤2ï¼šå‡†å¤‡æ•°æ®

```python
# æ•°æ®æ ¼å¼ç¤ºä¾‹
train_data = [
    {
        "text": "è®¢ä¸€å¼ æ˜å¤©å»åŒ—äº¬çš„æœºç¥¨",
        "intents": [1, 0, 0, 0, 0]  # äºŒè¿›åˆ¶å‘é‡
    },
    {
        "text": "è®¢æœºç¥¨å¹¶æŸ¥è¯¢å¤©æ°”",
        "intents": [1, 1, 0, 0, 0]
    }
]

# è½¬æ¢ä¸ºè®­ç»ƒæ ¼å¼
train_texts = [item["text"] for item in train_data]
train_labels = [item["intents"] for item in train_data]
```

### æ­¥éª¤3ï¼šåˆå§‹åŒ–æ¨¡å‹

```python
from transformers import AutoTokenizer

# é€‰æ‹©æ¨¡å‹
model_name = "bert-base-chinese"  # æˆ– "roberta-base"
num_intents = 10  # æ„å›¾ç±»åˆ«æ•°

# åˆå§‹åŒ–
model = MultiIntentTransformer(num_intents, model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)
```

### æ­¥éª¤4ï¼šè®­ç»ƒæ¨¡å‹

```python
from torch.utils.data import DataLoader

# åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
train_dataset = MultiIntentDataset(train_texts, train_labels, tokenizer)
val_dataset = MultiIntentDataset(val_texts, val_labels, tokenizer)
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# è®­ç»ƒ
trained_model = train_multi_intent_model(
    model, train_loader, val_loader,
    num_epochs=10,
    learning_rate=2e-5
)
```

### æ­¥éª¤5ï¼šæ¨ç†ä½¿ç”¨

```python
# åŠ è½½æ¨¡å‹
recognizer = CustomerServiceIntentRecognizer(
    model_path="best_model.pth",
    threshold=0.5
)

# è¯†åˆ«æ„å›¾
query = "æˆ‘è¦é€€æ¬¾å¹¶æŠ•è¯‰å•†å®¶"
intents = recognizer.recognize(query)
print(f"è¯†åˆ«åˆ°çš„æ„å›¾: {intents}")
```

### å¸¸è§é—®é¢˜

**Q1: å¦‚ä½•é€‰æ‹©åˆé€‚çš„é˜ˆå€¼ï¼Ÿ**
```python
# åœ¨éªŒè¯é›†ä¸Šå¯»æ‰¾æœ€ä¼˜é˜ˆå€¼
best_threshold, best_f1, _ = find_optimal_threshold(
    y_val_true, y_val_probs,
    metric='f1_macro'
)
print(f"æœ€ä¼˜é˜ˆå€¼: {best_threshold}, F1: {best_f1:.4f}")
```

**Q2: å¦‚ä½•å¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼Ÿ**
```python
# æ–¹æ³•1ï¼šä½¿ç”¨åŠ æƒæŸå¤±
pos_weights = compute_class_weights(y_train)
criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)

# æ–¹æ³•2ï¼šä½¿ç”¨Focal Loss
criterion = FocalLoss(alpha=0.25, gamma=2.0)
```

**Q3: å¦‚ä½•æå‡æ¨¡å‹æ€§èƒ½ï¼Ÿ**
```python
# 1. ä½¿ç”¨æ›´å¤§çš„é¢„è®­ç»ƒæ¨¡å‹
model = MultiIntentTransformer(num_intents, "roberta-large")

# 2. ä½¿ç”¨æ„å›¾æ„ŸçŸ¥æ³¨æ„åŠ›
model = IntentAwareModel(num_intents, "bert-base-chinese")

# 3. æ¨¡å‹é›†æˆ
ensemble = EnsembleMultiIntentModel([model1, model2, model3])
```

**Q4: å¦‚ä½•éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒï¼Ÿ**
```python
# 1. æ¨¡å‹é‡åŒ–ï¼ˆå‡å°‘æ¨¡å‹å¤§å°ï¼‰
from torch.quantization import quantize_dynamic
quantized_model = quantize_dynamic(model, {nn.Linear}, dtype=torch.qint8)

# 2. è½¬æ¢ä¸ºONNXï¼ˆè·¨å¹³å°éƒ¨ç½²ï¼‰
torch.onnx.export(
    model,
    (dummy_input_ids, dummy_attention_mask),
    "intent_model.onnx",
    input_names=['input_ids', 'attention_mask'],
    output_names=['logits']
)

# 3. ä½¿ç”¨TensorRTåŠ é€Ÿï¼ˆNVIDIA GPUï¼‰
# éœ€è¦å®‰è£… tensorrt å’Œ onnx-tensorrt
```

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **Multi-Intent Classification with Transformer Models**
   - ACL 2024: "Multi-Intent Recognition via Attention-based Graph Neural Networks"

2. **Focal Loss for Multi-Label Classification**
   - ICCV 2017: "Focal Loss for Dense Object Detection"
   - åº”ç”¨äºå¤šæ ‡ç­¾åˆ†ç±»çš„æ”¹è¿›ç‰ˆæœ¬

3. **Intent-Aware Attention Mechanisms**
   - EMNLP 2024: "Intent-Aware Multi-Intent Recognition with Transformer"

4. **Graph Neural Networks for Intent Relations**
   - ICLR 2025: "Modeling Intent Dependencies with Graph Convolutional Networks"

5. **LLM-based Zero-Shot Intent Recognition**
   - Recent work on using LLMs for multi-intent recognition without training

---

## ğŸ”— ç›¸å…³èµ„æº

- **æ•°æ®é›†**ï¼š
  - ATIS (Airline Travel Information System)
  - SNIPS (Multi-intent dataset)
  - MixATIS (Mixed intent dataset)

- **å¼€æºå®ç°**ï¼š
  - HuggingFace Transformers
  - PyTorch Lightning (è®­ç»ƒæ¡†æ¶)
  - Weights & Biases (å®éªŒè·Ÿè¸ª)

- **å·¥å…·åº“**ï¼š
  - `scikit-learn`: è¯„ä¼°æŒ‡æ ‡
  - `imbalanced-learn`: ç±»åˆ«ä¸å¹³è¡¡å¤„ç†
  - `torch-geometric`: å›¾ç¥ç»ç½‘ç»œ

---

*æœ€åæ›´æ–°ï¼š2025-12-07*
*å‚è€ƒï¼šACL 2024, EMNLP 2024, ICLR 2025 æœ€æ–°è®ºæ–‡*
*æ–‡æ¡£ç‰ˆæœ¬ï¼šv1.1*

## å…³æ³¨æˆ‘ï¼ŒAI ä¸å†éš¾ ğŸš€

